{"meta":{"title":"CatalpaFlat","subtitle":"CatalpaFlat","description":"IT technology has no end.","author":"CatalpaFlat","url":"https://blog.catalpaflat.cn"},"pages":[{"title":"","date":"2018-03-31T10:13:03.106Z","updated":"2018-03-31T10:13:03.106Z","comments":true,"path":"CNAME.html","permalink":"https://blog.catalpaflat.cn/CNAME.html","excerpt":"","text":"blog.catalpaflat.cn"},{"title":"404 Not Found：该页无法显示","date":"2018-04-02T05:32:56.284Z","updated":"2018-03-31T14:25:30.938Z","comments":false,"path":"/404.html","permalink":"https://blog.catalpaflat.cn//404.html","excerpt":"","text":""},{"title":"关于","date":"2018-04-02T05:32:40.753Z","updated":"2018-03-31T14:25:30.939Z","comments":false,"path":"about/index.html","permalink":"https://blog.catalpaflat.cn/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"书单","date":"2018-04-02T05:33:12.790Z","updated":"2018-03-31T14:25:30.939Z","comments":false,"path":"books/index.html","permalink":"https://blog.catalpaflat.cn/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-04-02T05:33:50.707Z","updated":"2018-03-31T14:25:30.939Z","comments":false,"path":"categories/index.html","permalink":"https://blog.catalpaflat.cn/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-04-02T05:33:24.507Z","updated":"2018-03-31T14:25:30.939Z","comments":true,"path":"links/index.html","permalink":"https://blog.catalpaflat.cn/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-04-02T05:33:40.596Z","updated":"2018-03-31T14:25:30.940Z","comments":false,"path":"tags/index.html","permalink":"https://blog.catalpaflat.cn/tags/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2018-04-02T05:28:47.206Z","updated":"2018-03-31T14:25:30.940Z","comments":false,"path":"repository/index.html","permalink":"https://blog.catalpaflat.cn/repository/index.html","excerpt":"","text":""},{"title":"My Works","date":"2017-05-31T02:05:56.000Z","updated":"2018-03-28T02:40:25.458Z","comments":true,"path":"works/index.html","permalink":"https://blog.catalpaflat.cn/works/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker run 命令","slug":"docker/命令/run","date":"2018-02-05T14:33:12.000Z","updated":"2018-03-28T13:31:13.256Z","comments":true,"path":"2018/02/05/docker/命令/run/","link":"","permalink":"https://blog.catalpaflat.cn/2018/02/05/docker/命令/run/","excerpt":"","text":"Docker run 命令 docker run ：创建一个新的容器并运行一个命令 1. 语法1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 1.1. OPTIONS说明 -a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； –name=”nginx-lb”: 为容器指定一个名称； –dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致； –dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致； -h “mars”: 指定容器的hostname； -e username=”ritchie”: 设置环境变量； –env-file=[]: 从指定文件读入环境变量； –cpuset=”0-2” or –cpuset=”0,1,2”: 绑定容器到指定CPU运行； -m :设置容器使用内存最大值； –net=”bridge”: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； –link=[]: 添加链接到另一个容器； –expose=[]: 开放一个端口或一组端口；1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889Run a command in a new containerOptions: --add-host value Add a custom host-to-IP mapping (host:ip) (default []) -a, --attach value Attach to STDIN, STDOUT or STDERR (default []) --blkio-weight value Block IO (relative weight), between 10 and 1000 --blkio-weight-device value Block IO weight (relative device weight) (default []) --cap-add value Add Linux capabilities (default []) --cap-drop value Drop Linux capabilities (default []) --cgroup-parent string Optional parent cgroup for the container --cidfile string Write the container ID to the file --cpu-percent int CPU percent (Windows only) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota -c, --cpu-shares int CPU shares (relative weight) --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) -d, --detach Run container in background and print container ID --detach-keys string Override the key sequence for detaching a container --device value Add a host device to the container (default []) --device-read-bps value Limit read rate (bytes per second) from a device (default []) --device-read-iops value Limit read rate (IO per second) from a device (default []) --device-write-bps value Limit write rate (bytes per second) to a device (default []) --device-write-iops value Limit write rate (IO per second) to a device (default []) --disable-content-trust Skip image verification (default true) --dns value Set custom DNS servers (default []) --dns-opt value Set DNS options (default []) --dns-search value Set custom DNS search domains (default []) --entrypoint string Overwrite the default ENTRYPOINT of the image -e, --env value Set environment variables (default []) --env-file value Read in a file of environment variables (default []) --expose value Expose a port or a range of ports (default []) --group-add value Add additional groups to join (default []) --health-cmd string Command to run to check health --health-interval duration Time between running the check (default 0s) --health-retries int Consecutive failures needed to report unhealthy --health-timeout duration Maximum time to allow one check to run (default 0s) --help Print usage -h, --hostname string Container host name -i, --interactive Keep STDIN open even if not attached --io-maxbandwidth string Maximum IO bandwidth limit for the system drive (Windows only) --io-maxiops uint Maximum IOps limit for the system drive (Windows only) --ip string Container IPv4 address (e.g. 172.30.100.104) --ip6 string Container IPv6 address (e.g. 2001:db8::33) --ipc string IPC namespace to use --isolation string Container isolation technology --kernel-memory string Kernel memory limit -l, --label value Set meta data on a container (default []) --label-file value Read in a line delimited file of labels (default []) --link value Add link to another container (default []) --link-local-ip value Container IPv4/IPv6 link-local addresses (default []) --log-driver string Logging driver for the container --log-opt value Log driver options (default []) --mac-address string Container MAC address (e.g. 92:d0:c6:0a:29:33) -m, --memory string Memory limit --memory-reservation string Memory soft limit --memory-swap string Swap limit equal to memory plus swap: '-1' to enable unlimited swap --memory-swappiness int Tune container memory swappiness (0 to 100) (default -1) --name string Assign a name to the container --network string Connect a container to a network (default \"default\") --network-alias value Add network-scoped alias for the container (default []) --no-healthcheck Disable any container-specified HEALTHCHECK --oom-kill-disable Disable OOM Killer --oom-score-adj int Tune host's OOM preferences (-1000 to 1000) --pid string PID namespace to use --pids-limit int Tune container pids limit (set -1 for unlimited) --privileged Give extended privileges to this container -p, --publish value Publish a container's port(s) to the host (default []) -P, --publish-all Publish all exposed ports to random ports --read-only Mount the container's root filesystem as read only --restart string Restart policy to apply when a container exits (default \"no\") --rm Automatically remove the container when it exits --runtime string Runtime to use for this container --security-opt value Security Options (default []) --shm-size string Size of /dev/shm, default value is 64MB --sig-proxy Proxy received signals to the process (default true) --stop-signal string Signal to stop a container, SIGTERM by default (default \"SIGTERM\") --storage-opt value Storage driver options for the container (default []) --sysctl value Sysctl options (default map[]) --tmpfs value Mount a tmpfs directory (default []) -t, --tty Allocate a pseudo-TTY --ulimit value Ulimit options (default []) -u, --user string Username or UID (format: &lt;name|uid&gt;[:&lt;group|gid&gt;]) --userns string User namespace to use --uts string UTS namespace to use -v, --volume value Bind mount a volume (default []) --volume-driver string Optional volume driver for the container --volumes-from value Mount volumes from the specified container(s) (default []) -w, --workdir string Working directory inside the container","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.catalpaflat.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.catalpaflat.cn/tags/docker/"}]},{"title":"Java 编码规范","slug":"java/Java开发规范","date":"2018-01-23T05:20:56.000Z","updated":"2018-03-28T12:57:49.869Z","comments":true,"path":"2018/01/23/java/Java开发规范/","link":"","permalink":"https://blog.catalpaflat.cn/2018/01/23/java/Java开发规范/","excerpt":"","text":"Java 编码规范 编写时间：2018.01.20编写人：CatalpaFlat 第1章 序言&emsp;&emsp;本规范的目的在于：建立一个可行可操作的编程标准、约定和指南，以规范公司java代码研发工作。&emsp;&emsp;为了提高公司研发能力，该规范的制定是为了规范java代码开发，提高java开发质量，从代码的层面规范并提高java项目的研发水平。该规范由Java技术小组制定，组织技术人员对重点项目以及新的java项目定期检查，对代码质量进行评估，对代码质量较差限期整改，并报Java技术小组组长备案作为项目考核依据。&emsp;&emsp;本规范的内容包括两个方面：编程规约、异常日志、单元测试、安全规约、工程结构、MySQL数据库六个维度。再根据内容特征，细分成若干二级子目录。&emsp;&emsp;为了开发者针对违规代码进行调整，根据约束力强弱及故障敏感性： 规约级别：强制、推荐、参考三大类； “说明”：对内容做了适当扩展和解释，对于规约条目的延伸信息中； “正例”：提倡什么样的编码和实现方式； “反例”：说明需要提防的雷区，以及真实的错误案例。 &emsp;&emsp;本规范解释权归Java技术小组，属于Java技术小组为了提供公司研发水平以及质量的一系列措施中的一部分，在后续的版本中将根据具体需要进行修改以及调整。技术小组审核后给出相应的整改意见，对于有争议的问题，可直接与Java技术小组组长沟通。 第2章 编程规约2.1 命名规范1.【强制】代码中的命名均不能以下划线或美元符号开始，也不能以下划线或美元符号结束。&emsp;反例：name/__name/$Object/name/name$/Object$2.【强制】代码中的命名严禁使用拼音与英文混合的方式，更不允许直接使用中文的方式。&emsp;说明：正确的英文拼写和语法可以让阅读者易于理解，避免歧义。注意，即使纯拼音命名方式也要避免采用。&emsp;正例：alibaba / taobao / youku / hangzhou 等国际通用的名称，可视同英文。&emsp;反例：DaZhePromotion [打折] / getPingfenByName() [评分] / int 某变量 = 33.【强制】类名使用UpperCamelCase风格，必须遵从驼峰形式，但以下情形例外：DO / BO / DTO / VO / AO / TO&emsp;正例：MarcoPolo / UserDO / XmlService / TcpUdpDeal / TaPromotion&emsp;反例：macroPolo / UserDo / XMLService / TCPUDPDeal / TAPromotion4.【强制】方法名、参数名、成员变量、局部变量都统一使用lowerCamelCase风格，必须遵从驼峰形式。&emsp;正例： localValue / getHttpMessage() / inputUserId5.【强制】常量命名全部大写，单词间用下划线隔开，力求语义表达完整清楚，不要嫌名字长。&emsp;正例：MAX_STOCK_COUNT&emsp;反例：MAX_COUNT6.【强制】抽象类命名使用Abstract或Base开头；异常类命名使用Exception结尾；测试类命名以它要测试的类的名称开始，以Test结尾。7.【强制】中括号是数组类型的一部分，&emsp;正例：数组定义如下：String[] args;&emsp;反例：使用String args[]的方式来定义。8.【强制】POJO类中布尔类型的变量，都不要加is，否则部分框架解析会引起序列化错误。&emsp;反例：定义为基本数据类型Boolean isDeleted；的属性，它的方法也是isDeleted()，RPC框架在反向解析的时候，“以为”对应的属性名称是deleted，导致属性获取不到，进而抛出异常。9.【强制】包名统一使用小写，点分隔符之间有且仅有一个自然语义的英语单词。包名统一使用单数形式，但是类名如果有复数含义，类名可以使用复数形式。&emsp;正例： 应用工具类包名为com.alibaba.open.util、类名为MessageUtils（此规则参考spring的框架结构）10.【强制】杜绝完全不规范的缩写，避免望文不知义。&emsp;反例：AbstractClass“缩写”命名成AbsClass；condition“缩写”命名成 condi，此类随意缩写严重降低了代码的可阅读性。11.【推荐】为了达到代码自解释的目标，任何自定义编程元素在命名时，使用尽量完整的单词组合来表达其意。&emsp;正例：从远程仓库拉取代码的类命名为PullCodeFromRemoteRepository。&emsp;反例：变量int a; 的随意命名方式。12.【推荐】如果模块、接口、类、方法使用了设计模式，在命名时体现出具体模式。&emsp;说明：将设计模式体现在名字中，有利于阅读者快速理解架构设计理念。&emsp;正例：public class OrderFactory; public class LoginProxy; public class ResourceObserver;13.【推荐】接口类中的方法和属性不要加任何修饰符号（public 也不要加），保持代码的简洁性，并加上有效的Javadoc注释。尽量不要在接口里定义变量，如果一定要定义变量，肯定是与接口方法相关，并且是整个应用的基础常量。&emsp;正例：接口方法签名：void f(); 接口基础常量表示：String COMPANY = “alibaba”;&emsp;反例：接口方法定义：public abstract void f();&emsp;说明：JDK8中接口允许有默认实现，那么这个default方法，是对所有实现类都有价值的默认实现。14.接口和实现类的命名有两套规则： &emsp;1）【强制】对于Service和DAO类，基于SOA的理念，暴露出来的服务一定是接口，内部的实现类用Impl的后缀与接口区别。&emsp;&emsp;正例：CacheServiceImpl实现CacheService接口。&emsp; 2）【推荐】如果是形容能力的接口名称，取对应的形容词做接口名（通常是–able的形式）。&emsp;&emsp;正例：AbstractTranslator实现 Translatable。15.【参考】枚举类名建议带上Enum后缀，枚举成员名称需要全大写，单词间用下划线隔开。&emsp;说明：枚举其实就是特殊的常量类，且构造方法被默认强制是私有。&emsp;正例：枚举名字为ProcessStatusEnum的成员名称：SUCCESS / UNKOWN_REASON。16.【参考】各层命名规约：&emsp;A) Service/DAO层方法命名规约:&emsp;&emsp;1） 获取单个对象的方法用get做前缀。&emsp;&emsp;2） 获取多个对象的方法用list做前缀。&emsp;&emsp;3） 获取统计值的方法用count做前缀。&emsp;&emsp;4） 插入的方法用save/insert做前缀。&emsp;&emsp;5） 删除的方法用remove/delete做前缀。&emsp;&emsp;6） 修改的方法用update做前缀。&emsp;B) 领域模型命名规约:&emsp;&emsp;1） 数据对象：xxxDO，xxx即为数据表名。&emsp;&emsp;2） 数据传输对象：xxxDTO，xxx为业务领域相关的名称。&emsp;&emsp;3） 展示对象：xxxVO，xxx一般为网页名称。&emsp;&emsp;4） POJO是DO/DTO/BO/VO的统称，禁止命名成xxxPOJO。 2.2 常量定义1.【强制】不允许任何魔法值（即未经定义的常量）直接出现在代码中。&emsp;反例：String key = “Id#taobao_” + tradeId; cache.put(key, value);2.【强制】long或者Long初始赋值时，使用大写的L，不能是小写的l，小写容易跟数字1混淆，造成误解。&emsp;说明：Long a = 2l; 写的是数字的21，还是Long型的2?3.【推荐】不要使用一个常量类维护所有常量，按常量功能进行归类，分开维护。&emsp;说明：大而全的常量类，非得使用查找功能才能定位到修改的常量，不利于理解和维护。&emsp;正例：缓存相关常量放在类CacheConsts下；系统配置相关常量放在类ConfigConsts下。4.【推荐】常量的复用层次有五层：跨应用共享常量、应用内共享常量、子工程内共享常量、包内共享常量、类内共享常量。&emsp;1） 跨应用共享常量：放置在二方库中，通常是client.jar中的constant目录下。&emsp;2） 应用内共享常量：放置在一方库中，通常是modules中的constant目录下。&emsp;反例：易懂变量也要统一定义成应用内共享常量，两位攻城师在两个类中分别定义了表示“是”的变量： 1234//类A中：public static final String YES = &quot;yes&quot;;//类B中：public static final String YES = &quot;y&quot;; 123456789 A.YES.equals(B.YES);//预期是true，但实际返回为false，导致线上问题。 ``` &amp;emsp;3） 子工程内部共享常量：即在当前子工程的constant目录下。 &amp;emsp;4） 包内共享常量：即在当前包下单独的constant目录下。 &amp;emsp;5） 类内共享常量：直接在类内部private static final定义。 5.【推荐】如果变量值仅在一个范围内变化，且带有名称之外的延伸属性，定义为枚举类。下面正例中的数字就是延伸信息，表示星期几。 正例： public Enum { MONDAY(1), TUESDAY(2), WEDNESDAY(3), THURSDAY(4), FRIDAY(5), SATURDAY(6), SUNDAY(7); } 1234567891011121314151617### 2.3 代码格式1.【强制】大括号的使用约定。如果是大括号内为空，则简洁地写成&#123;&#125;即可，不需要换行；如果是非空代码块则： &amp;emsp;1） 左大括号前不换行。 &amp;emsp;2） 左大括号后换行。 &amp;emsp;3） 右大括号前换行。 &amp;emsp;4） 右大括号后还有else等代码则不换行；表示终止的右大括号后必须换行。 2.【强制】 左小括号和字符之间不出现空格；同样，右小括号和字符之间也不出现空格。详见第5条下方正例提示。 &amp;emsp;反例：if (空格a == b空格) 3.【强制】if/for/while/switch/do等保留字与括号之间都必须加空格。 4.【强制】任何二目、三目运算符的左右两边都需要加一个空格。 &amp;emsp;说明：运算符包括赋值运算符=、逻辑运算符&amp;&amp;、加减乘除符号等。 5.【强制】采用4个空格缩进，禁止使用tab字符。 &amp;emsp;说明：如果使用tab缩进，必须设置1个tab为4个空格。IDEA设置tab为4个空格时，请勿勾选Use tab character；而在eclipse中，必须勾选insert spaces for tabs。 &amp;emsp;正例： （涉及1-5点） public static void main(String[] args) { // 缩进4个空格 String say = &quot;hello&quot;; // 运算符的左右必须有一个空格 int flag = 0; // 关键词if与括号之间必须有一个空格，括号内的f与左括号，0与右括号不需要空格 if (flag == 0) { System.out.println(say); } // 左大括号前加空格且不换行；左大括号后换行 if (flag == 1) { System.out.println(&quot;world&quot;); // 右大括号前换行，右大括号后有else，不用换行 } else { System.out.println(&quot;ok&quot;); // 在右大括号后直接结束，则必须换行 } } 123456789106.【强制】注释的双斜线与注释内容之间有且仅有一个空格。 &amp;emsp;正例：// 注释内容，注意在//和注释内容之间有一个空格。 7.【强制】单行字符数限制不超过120个，超出需要换行，换行时遵循如下原则： &amp;emsp;1） 第二行相对第一行缩进4个空格，从第三行开始，不再继续缩进，参考示例。 &amp;emsp;2） 运算符与下文一起换行。 &amp;emsp;3） 方法调用的点符号与下文一起换行。 &amp;emsp;4） 方法调用时，多个参数，需要换行时，在逗号后进行。 &amp;emsp;5） 在括号前不要换行，见反例。 &amp;emsp;正例： StringBuffer sb = new StringBuffer(); // 超过120个字符的情况下，换行缩进4个空格，点号和方法名称一起换行 sb.append(&quot;zi&quot;).append(&quot;xin&quot;)... .append(&quot;huang&quot;)... .append(&quot;huang&quot;)... .append(&quot;huang&quot;); 1&amp;emsp;反例： StringBuffer sb = new StringBuffer(); // 超过120个字符的情况下，不要在括号前换行 sb.append(&quot;zi&quot;).append(&quot;xin&quot;)...append (&quot;huang&quot;); // 参数很多的方法调用可能超过120个字符，不要在逗号前换行 method(args1, args2, args3, ... , argsX); 128.【强制】方法参数在定义和传入时，多个参数逗号后边必须加空格。 &amp;emsp;正例：下例中实参的&quot;a&quot;,后边必须要有一个空格。 method(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;); 1239.【强制】IDE的text file encoding设置为UTF-8; IDE中文件的换行符使用Unix格式，不要使用Windows格式。 10.【推荐】没有必要增加若干空格来使某一行的字符与上一行对应位置的字符对齐。 &amp;emsp;正例： int a = 3; long b = 4L; float c = 5F; StringBuffer sb = new StringBuffer(); 123456789101112&amp;emsp;说明：增加sb这个变量，如果需要对齐，则给a、b、c都要增加几个空格，在变量比较多的情况下，是一种累赘的事情。 11.【推荐】方法体内的执行语句组、变量的定义语句组、不同的业务逻辑之间或者不同的语义之间插入一个空行。相同业务逻辑和语义之间不需要插入空行。 &amp;emsp;说明：没有必要插入多个空行进行隔开。 ### 2.4 OOP规约1.【强制】避免通过一个类的对象引用访问此类的静态变量或静态方法，无谓增加编译器解析成本，直接用类名来访问即可。 2.【强制】所有的覆写方法，必须加@Override注解。 &amp;emsp;说明：getObject()与get0bject()的问题。一个是字母的O，一个是数字的0，加@Override可以准确判断是否覆盖成功。另外，如果在抽象类中对方法签名进行修改，其实现类会马上编译报错。 3.【强制】相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object。 &amp;emsp;说明：可变参数必须放置在参数列表的最后。（提倡同学们尽量不用可变参数编程） 正例： public User getUsers(String type, Integer... ids) {...} 12345678910111213141516171819202122232425264.【强制】外部正在调用或者二方库依赖的接口，不允许修改方法签名，避免对接口调用方产生影响。接口过时必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。 5.【强制】不能使用过时的类或方法。 &amp;emsp;说明：java.net.URLDecoder 中的方法decode(String encodeStr) 这个方法已经过时，应该使用双参数decode(String source, String encode)。接口提供方既然明确是过时接口，那么有义务同时提供新的接口；作为调用方来说，有义务去考证过时方法的新实现是什么。 6.【强制】Object的equals方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals。 &amp;emsp;正例：&quot;test&quot;.equals(object); &amp;emsp;反例：object.equals(&quot;test&quot;); &amp;emsp;说明：推荐使用java.util.Objects#equals（JDK7引入的工具类） 7.【强制】所有的相同类型的包装类对象之间值的比较，全部使用equals方法比较。 &amp;emsp;说明：对于Integer var = ? 在-128至127范围内的赋值，Integer对象是在IntegerCache.cache产生，会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用equals方法进行判断。 8.关于基本数据类型与包装数据类型的使用标准如下： &amp;emsp;1） 【强制】所有的POJO类属性必须使用包装数据类型。 &amp;emsp;2） 【强制】RPC方法的返回值和参数必须使用包装数据类型。 &amp;emsp;3） 【推荐】所有的局部变量使用基本数据类型。 &amp;emsp;说明：POJO类属性没有初值是提醒使用者在需要使用时，必须自己显式地进行赋值，任何NPE问题，或者入库检查，都由使用者来保证。 &amp;emsp;正例：数据库的查询结果可能是null，因为自动拆箱，用基本数据类型接收有NPE风险。 &amp;emsp;反例：比如显示成交总额涨跌情况，即正负x%，x为基本数据类型，调用的RPC服务，调用不成功时，返回的是默认值，页面显示为0%，这是不合理的，应该显示成中划线。所以包装数据类型的null值，能够表示额外的信息，如：远程调用失败，异常退出。 9.【强制】定义DO/DTO/VO等POJO类时，不要设定任何属性默认值。 &amp;emsp;反例：POJO类的gmtCreate默认值为new Date();但是这个属性在数据提取时并没有置入具体值，在更新其它字段时又附带更新了此字段，导致创建时间被修改成当前时间。 10.【强制】序列化类新增属性时，请不要修改serialVersionUID字段，避免反序列失败；如果完全不兼容升级，避免反序列化混乱，那么请修改serialVersionUID值。 &amp;emsp;说明：注意serialVersionUID不一致会抛出序列化运行时异常。 11.【强制】构造方法里面禁止加入任何业务逻辑，如果有初始化逻辑，请放在init方法中。 12.【强制】POJO类必须写toString方法。使用IDE的中工具：source&gt; generate toString时，如果继承了另一个POJO类，注意在前面加一下super.toString。 &amp;emsp;说明：在方法执行抛出异常时，可以直接调用POJO的toString()方法打印其属性值，便于排查问题。 13.【推荐】使用索引访问用String的split方法得到的数组时，需做最后一个分隔符后有无内容的检查，否则会有抛IndexOutOfBoundsException的风险。 &amp;emsp;说明： String str = &quot;a,b,c,,&quot;; String[] ary = str.split(&quot;,&quot;); // 预期大于3，结果是3 System.out.println(ary.length); 12345614.【推荐】当一个类有多个构造方法，或者多个同名方法，这些方法应该按顺序放置在一起，便于阅读，此条规则优先于第15条规则。 15.【推荐】 类内方法定义顺序依次是：公有方法或保护方法 &gt; 私有方法 &gt; getter/setter方法。 &amp;emsp;说明：公有方法是类的调用者和维护者最关心的方法，首屏展示最好；保护方法虽然只是子类关心，也可能是“模板设计模式”下的核心方法；而私有方法外部一般不需要特别关心，是一个黑盒实现；因为承载的信息价值较低，所有Service和DAO的getter/setter方法放在类体最后。 16.【推荐】setter方法中，参数名称与类成员变量名称一致，this.成员名 = 参数名。在getter/setter方法中，不要增加业务逻辑，增加排查问题的难度。 &amp;emsp;反例： public Integer getData() { if (true) { return this.data + 100; } else { return this.data - 100; } } 123417.【推荐】循环体内，字符串的连接方式，使用StringBuilder的append方法进行扩展。 &amp;emsp;说明：反编译出的字节码文件显示每次循环都会new出一个StringBuilder对象，然后进行append操作，最后通过toString方法返回String对象，造成内存资源浪费。 &amp;emsp;反例： String str = &quot;start&quot;; for (int i = 0; i &lt; 100; i++) { str = str + &quot;hello&quot;; } 12345678910111213141516171819202122232425262728293031323318.【推荐】final可以声明类、成员变量、方法、以及本地变量，下列情况使用final关键字： &amp;emsp;1） 不允许被继承的类，如：String类。 &amp;emsp;2） 不允许修改引用的域对象，如：POJO类的域变量。 &amp;emsp;3） 不允许被重写的方法，如：POJO类的setter方法。 &amp;emsp;4） 不允许运行过程中重新赋值的局部变量。 &amp;emsp;5） 避免上下文重复使用一个变量，使用final描述可以强制重新定义一个变量，方便更好地进行重构。 19.【推荐】慎用Object的clone方法来拷贝对象。 &amp;emsp;说明：对象的clone方法默认是浅拷贝，若想实现深拷贝需要重写clone方法实现属性对象的拷贝。 20.【推荐】类成员与方法访问控制从严： &amp;emsp;1） 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。 &amp;emsp;2） 工具类不允许有public或default构造方法。 &amp;emsp;3） 类非static成员变量并且与子类共享，必须是protected。 &amp;emsp;4） 类非static成员变量并且仅在本类使用，必须是private。 &amp;emsp;5） 类static成员变量如果仅在本类使用，必须是private。 &amp;emsp;6） 若是static成员变量，必须考虑是否为final。 &amp;emsp;7） 类成员方法只供类内部调用，必须是private。 &amp;emsp;8） 类成员方法只对继承类公开，那么限制为protected。 &amp;emsp;说明：任何类、方法、参数、变量，严控访问范围。过于宽泛的访问范围，不利于模块解耦。思考：如果是一个private的方法，想删除就删除，可是一个public的service方法，或者一个public的成员变量，删除一下，不得手心冒点汗吗？变量像自己的小孩，尽量在自己的视线内，变量作用域太大，无限制的到处跑，那么你会担心的。 ### 2.5 集合规约 1.【强制】关于hashCode和equals的处理，遵循如下规则： &amp;emsp;1） 只要重写equals，就必须重写hashCode。 &amp;emsp;2） 因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须重写这两个方法。 &amp;emsp;3） 如果自定义对象做为Map的键，那么必须重写hashCode和equals。说明：String重写了hashCode和equals方法，所以我们可以非常愉快地使用String对象作为key来使用。 2.【强制】 ArrayList的subList结果不可强转成ArrayList，否则会抛出ClassCastException异常，即java.util.RandomAccessSubList cannot be cast to java.util.ArrayList. &amp;emsp;说明：subList 返回的是 ArrayList 的内部类 SubList，并不是 ArrayList ，而是 ArrayList 的一个视图，对于SubList子列表的所有操作最终会反映到原列表上。 3.【强制】在subList场景中，高度注意对原集合元素个数的修改，会导致子列表的遍历、增加、删除均会产生ConcurrentModificationException 异常。 4.【强制】使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一样的数组，大小就是list.size()。 &amp;emsp;说明：使用toArray带参方法，入参分配的数组空间不够大时，toArray方法内部将重新分配内存空间，并返回新数组地址；如果数组元素大于实际所需，下标为[ list.size() ]的数组元素将被置为null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素个数一致。 &amp;emsp;正例： List&lt;String&gt; list = new ArrayList&lt;String&gt;(2); list.add(&quot;guan&quot;); list.add(&quot;bao&quot;); String[] array = new String[list.size()]; array = list.toArray(array); 1234&amp;emsp;反例：直接使用toArray无参方法存在问题，此方法返回值只能是Object[]类，若强转其它类型数组将出现ClassCastException错误。 5.【强制】使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的add/remove/clear方法会抛出 UnsupportedOperationException异常。 &amp;emsp;说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。 String[] str = new String[] { &quot;you&quot;, &quot;wu&quot; }; List list = Arrays.asList(str); 123456789&amp;emsp;&amp;emsp;第一种情况：list.add(&quot;yangguanbao&quot;); 运行时异常。 &amp;emsp;&amp;emsp;第二种情况：str[0] = &quot;gujin&quot;; 那么list.get(0)也会随之修改。 6.【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用add方法，而&lt;? super T&gt;不能使用get方法，做为接口调用赋值时易出错。 &amp;emsp;说明：扩展说一下PECS(Producer Extends Consumer Super)原则： &amp;emsp;&amp;emsp;第一、频繁往外读取内容的，适合用&lt;? extends T&gt;。 &amp;emsp;&amp;emsp;第二、经常往里插入的，适合用&lt;? super T&gt;。 7.【强制】不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator方式，如果并发操作，需要对Iterator对象加锁。 &amp;emsp;正例： Iterator iterator = list.iterator(); while (iterator.hasNext()) { String item = iterator.next(); if (删除元素的条件) { iterator.remove(); } }12&amp;emsp;反例： List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;1&quot;); list.add(&quot;2&quot;); for (String item : list) { if (&quot;1&quot;.equals(item)) { list.remove(item); } } 12345678&amp;emsp;说明：以上代码的执行结果肯定会出乎大家的意料，那么试一下把“1”换成“2”，会是同样的结果吗？ 8.【强制】 在JDK7版本及以上，Comparator要满足如下三个条件，不然Arrays.sort，Collections.sort会报IllegalArgumentException异常。 &amp;emsp;说明：三个条件如下 &amp;emsp;&amp;emsp;1） x，y的比较结果和y，x的比较结果相反。 &amp;emsp;&amp;emsp;2） x&gt;y，y&gt;z，则x&gt;z。 &amp;emsp;&amp;emsp;3） x=y，则x，z比较结果和y，z比较结果相同。 &amp;emsp;反例：下例中没有处理相等的情况，实际使用中可能会出现异常： new Comparator&lt;Student&gt;() { @Override public int compare(Student o1, Student o2) { return o1.getId() &gt; o2.getId() ? 1 : -1; } }; 1234567891011121314151617181920212223242526279.【推荐】集合初始化时，指定集合初始值大小。 &amp;emsp;说明：HashMap使用HashMap(int initialCapacity) 初始化， &amp;emsp;正例：initialCapacity =(需要存储的元素个数 / 负载因子) + 1。注意负载因子（即loader factor）默认为0.75，如果暂时无法确定初始值大小，请设置为16（即默认值）。 &amp;emsp;反例：HashMap需要放置1024个元素，由于没有设置容量初始大小，随着元素不断增加，容量7次被迫扩大，resize需要重建hash表，严重影响性能。 10.【推荐】使用entrySet遍历Map类集合KV，而不是keySet方式进行遍历。 &amp;emsp;说明：keySet其实是遍历了2次，一次是转为Iterator对象，另一次是从hashMap中取出key所对应的value。而entrySet只是遍历了一次就把key和value都放到了entry中，效率更高。如果是JDK8，使用Map.foreach方法。&amp;emsp;正例：values()返回的是V值集合，是一个list集合对象；keySet()返回的是K值集合，是一个Set集合对象；entrySet()返回的是K-V值组合集合。 11.【推荐】高度注意Map类集合K/V能不能存储null值的情况，如下表格： | 集合类 | Key | Value | Super | 说明|----|----|----|----|----||Hashtable | 不允许为null| 不允许为null | Dictionary| 线程安全|ConcurrentHashMap |不允许为null |不允许为null |AbstractMap | 锁分段技术（JDK8:CAS）|TreeMap |不允许为null| 允许为null | AbstractMap | 线程不安全|HashMap | 允许为null | 允许为null | AbstractMap | 线程不安全&amp;emsp;反例： 由于HashMap的干扰，很多人认为ConcurrentHashMap是可以置入null值，而事实上，存储null值时会抛出NPE异常。 12.【参考】合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳定性(unorder)带来的负面影响。 &amp;emsp;说明：有序性是指遍历的结果是按某种比较规则依次排列的。稳定性指集合每次遍历的元素次序是一定的。如：ArrayList是order/unsort；HashMap是unorder/unsort；TreeSet是order/sort。 13.【参考】利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的contains方法进行遍历、对比、去重操作。 ### 2.6 并发规约1.【强制】获取单例对象需要保证线程安全，其中的方法也要保证线程安全。 &amp;emsp;说明：资源驱动类、工具类、单例工厂类都需要注意。 2.【强制】创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。 &amp;emsp;正例： public class TimerTaskThread extends Thread { public TimerTaskThread() { super.setName(&quot;TimerTaskThread&quot;); ... } } 12345678910113.【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。 &amp;emsp;说明：使用线程池的好处是减少在创建和销毁线程上所花的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。 4.【强制】线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 &amp;emsp;说明：Executors返回的线程池对象的弊端如下： &amp;emsp;&amp;emsp;1）FixedThreadPool和SingleThreadPool:允许的请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，从而导致OOM。 &amp;emsp;&amp;emsp;2）CachedThreadPool和ScheduledThreadPool:允许的创建线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM。5.【强制】SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，必须加锁，或者使用DateUtils工具类。 &amp;emsp;正例：注意线程安全，使用DateUtils。亦推荐如下处理： private static final ThreadLocal&lt;DateFormat&gt; df = new ThreadLocal&lt;DateFormat&gt;() { @Override protected DateFormat initialValue() { return new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); } }; 12345678910111213141516&amp;emsp;说明：如果是JDK8的应用，可以使用Instant代替Date，LocalDateTime代替Calendar，DateTimeFormatter代替SimpleDateFormat，官方给出的解释：simple beautiful strong immutable thread-safe。 6.【强制】高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁。 &amp;emsp;说明：尽可能使加锁的代码块工作量尽可能的小，避免在锁代码块中调用RPC方法。 7.【强制】对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。 &amp;emsp;说明：线程一需要对表A、B、C依次全部加锁后才可以进行更新操作，那么线程二的加锁顺序也必须是A、B、C，否则可能出现死锁。 8.【强制】并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用version作为更新依据。 &amp;emsp;说明：如果每次访问冲突概率小于20%，推荐使用乐观锁，否则使用悲观锁。乐观锁的重试次数不得小于3次。 9.【强制】多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，使用ScheduledExecutorService则没有这个问题。 10.【推荐】使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至await方法，直到超时才返回结果。 &amp;emsp;说明：注意，子线程抛出异常堆栈，不能在主线程try-catch到。 11.【推荐】避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed 导致的性能下降。 &amp;emsp;说明：Random实例包括java.util.Random 的实例或者 Math.random()的方式。 &amp;emsp;正例：在JDK7之后，可以直接使用API ThreadLocalRandom，而在 JDK7之前，需要编码保证每个线程持有一个实例。 12.【推荐】在并发场景下，通过双重检查锁（double-checked locking）实现延迟初始化的优化问题隐患(可参考 The &quot;Double-Checked Locking is Broken&quot; Declaration)，推荐解决方案中较为简单一种（适用于JDK5及以上版本），将目标属性声明为 volatile型。 &amp;emsp;反例： class Singleton { private Helper helper = null; public Helper getHelper() { if (helper == null) synchronized(this) { if (helper == null) helper = new Helper(); } return helper; } // other methods and fields... } 1234567891013.【参考】volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题。如果是count++操作，使用如下类实现：AtomicInteger count = new AtomicInteger(); count.addAndGet(1); 如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观锁的重试次数）。 14.【参考】HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在开发过程中可以使用其它数据结构或加锁来规避此风险。 15.【参考】ThreadLocal无法解决共享对象的更新问题，ThreadLocal对象建议使用static修饰。这个变量是针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享此静态变量 ，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象(只要是这个线程内定义的)都可以操控这个变量。 ### 2.7 控制语句1.【强制】在一个switch块内，每个case要么通过break/return等来终止，要么注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default语句并且放在最后，即使它什么代码也没有。 2.【强制】在if/else/for/while/do语句中必须使用大括号。即使只有一行代码，避免采用单行的编码方式：if (condition) statements; 3.【推荐】表达异常的分支时，少用if-else方式，这种方式可以改写成： if (condition) { … return obj; } // 接着写else的业务逻辑代码;12&amp;emsp;说明：如果非得使用if()...else if()...else...方式表达逻辑，【强制】避免后续代码维护困难，请勿超过3层。 &amp;emsp;正例：超过3层的 if-else 的逻辑判断代码可以使用卫语句、策略模式、状态模式等来实现，其中卫语句示例如下： public void today() { if (isBusy()) { System.out.println(“change time.”); return; } if (isFree()) { System.out.println(“go to travel.”); retur } System.out.println(“stay at home to learn Alibaba Java Coding Guidelines.”); return;}1234.【推荐】除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性。 &amp;emsp;说明：很多if语句内的逻辑相当复杂，阅读者需要分析条件表达式的最终结果，才能明确什么样的条件执行什么样的语句，那么，如果阅读者分析逻辑表达式错误呢？ &amp;emsp;正例： // 伪代码如下final boolean existed = (file.open(fileName, “w”) != null) &amp;&amp; (…) || (…);if (existed) {…}反例： if ((file.open(fileName, “w”) != null) &amp;&amp; (…) || (…)) {…}1234567891011121314151617181920212223242526272829303132333435365.【推荐】循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。 6.【推荐】接口入参保护，这种场景常见的是用于做批量操作的接口。 7.【参考】下列情形，需要进行参数校验： &amp;emsp;1） 调用频次低的方法。 &amp;emsp;2） 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致中间执行回退，或者错误，那得不偿失。 &amp;emsp;3） 需要极高稳定性和可用性的方法。 &amp;emsp;4） 对外提供的开放接口，不管是RPC/API/HTTP接口。 &amp;emsp;5） 敏感权限入口。 8.【参考】下列情形，不需要进行参数校验： &amp;emsp;1） 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查要求。 &amp;emsp;2） 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可以省略。 &amp;emsp;3） 被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检查或者肯定不会有问题，此时可以不校验参数。 ### 2.8 注释规约1.【强制】类、类属性、类方法的注释必须使用Javadoc规范，使用/** 内容*/格式，不得使用// xxx方式。 &amp;emsp;说明：在IDE编辑窗口中，Javadoc方式会提示相关注释，生成Javadoc可以正确输出相应注释；在IDE中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。 2.【强制】所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能。 说明：对子类的实现要求，或者调用注意事项，请一并说明。 3.【强制】所有的类都必须添加创建者和创建日期。 4.【强制】方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使用&apos;/*&apos; &apos;*/&apos;注释，注意与代码对齐。 5.【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。 6.【推荐】与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可。 &amp;emsp;反例：“TCP连接超时”解释成“传输控制协议连接超时”，理解反而费脑筋。 7.【推荐】代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改。 &amp;emsp;说明：代码与注释更新不同步，就像路网与导航软件更新不同步一样，如果导航软件严重滞后，就失去了导航的意义。 8.【参考】谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。 &amp;emsp;说明：代码被注释掉有两种可能性： &amp;emsp;&amp;emsp;1）后续会恢复此段代码逻辑。 &amp;emsp;&amp;emsp;2）永久不用。前者如果没有备注信息，难以知晓注释动机。后者建议直接删掉（代码仓库保存了历史代码）。 9.【参考】对于注释的要求： &amp;emsp;第一、能够准确反应设计思想和代码逻辑； &amp;emsp;第二、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看的，使其能够快速接替自己的工作。 10.【参考】好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释是相当大的负担。 反例： // put elephant into fridgeput(elephant, fridge);`方法名put，加上两个有意义的变量名elephant和fridge，已经说明了这是在干什么，语义清晰的代码不需要额外的注释。 11.【参考】特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，经常清理此类标记。线上故障有时候就是来源于这些标记处的代码。&emsp;1） 待办事宜（TODO）:（ 标记人，标记时间，[预计处理时间]） 表示需要实现，但目前还未实现的功能。这实际上是一个Javadoc的标签，目前的Javadoc还没有实现，但已经被广泛使用。只能应用于类，接口和方法（因为它是一个Javadoc标签）。&emsp;2） 错误，不能工作（FIXME）:（标记人，标记时间，[预计处理时间]） 在注释中用FIXME标记某代码是错误的，而且不能工作，需要及时纠正的情况。 第3章 异常日志3.1 异常处理","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/tags/Java/"}]},{"title":"CentOS Docker 安装","slug":"docker/安装/docker安装","date":"2018-01-05T08:33:56.000Z","updated":"2018-03-28T13:29:28.509Z","comments":true,"path":"2018/01/05/docker/安装/docker安装/","link":"","permalink":"https://blog.catalpaflat.cn/2018/01/05/docker/安装/docker安装/","excerpt":"","text":"CentOS Docker 安装 Docker支持以下的CentOS版本： CentOS 7 (64-bit) CentOS 6.5 (64-bit) 或更高的版本 前提条件:目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。Docker 运行在 CentOS-6.5 或更高的版本的 CentOS 上，要求系统为64位、系统内核版本为 2.6.32-431 或者更高版本。使用 yum 安装（CentOS 7下） 1. 检测版本Docker 要求 CentOS 系统的内核版本高于 3.10 ，查看本页面的前提条件来验证你的CentOS 版本是否支持 Docker 。通过 uname -r 命令查看你当前的内核版本1uname -r 2. 安装 DockerDocker 软件包和依赖包已经包含在默认的 CentOS-Extras 软件源里，安装命令如下：1yum -y install docker 3. 启动 Docker 后台服务1service docker start 4.镜像加速鉴于国内网络问题，后续拉取 Docker 镜像十分缓慢，我们可以需要配置加速器来解决，我使用的是网易的镜像地址：http://hub-mirror.c.163.com。新版的 Docker 使用 /etc/docker/daemon.json（Linux） 或者 %programdata%\\docker\\config\\daemon.json（Windows） 来配置 Daemon。请在该配置文件中加入（没有该文件的话，请先建一个）：{ “registry-mirrors”: [“http://hub-mirror.c.163.com&quot;]}","categories":[{"name":"docker","slug":"docker","permalink":"https://blog.catalpaflat.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://blog.catalpaflat.cn/tags/docker/"}]},{"title":"Java 实现中文-拼音转换","slug":"java/Java 实现中文-拼音转换","date":"2017-12-16T02:16:56.000Z","updated":"2018-03-28T12:55:25.101Z","comments":true,"path":"2017/12/16/java/Java 实现中文-拼音转换/","link":"","permalink":"https://blog.catalpaflat.cn/2017/12/16/java/Java 实现中文-拼音转换/","excerpt":"","text":"Java 实现中文-拼音转换/** * 中文转拼音 * * @author ： CatalpaFlat */ public class ChineseToPinyinUtil { /** * 将文字转为汉语拼音 * * @param chineseLanguage 要转成拼音的中文 */ public static String toHanyuPinyin(String chineseLanguage) { char[] clChars = chineseLanguage.trim().toCharArray(); StringBuilder hanyupinyin = new StringBuilder(); HanyuPinyinOutputFormat defaultFormat = new HanyuPinyinOutputFormat(); // 输出拼音全部小写 defaultFormat.setCaseType(HanyuPinyinCaseType.LOWERCASE); // 不带声调 defaultFormat.setToneType(HanyuPinyinToneType.WITHOUT_TONE); defaultFormat.setVCharType(HanyuPinyinVCharType.WITH_V); try { for (char clChar : clChars) { // 如果字符是中文,则将中文转为汉语拼音 if (String.valueOf(clChar).matches(&quot;[\\u4e00-\\u9fa5]+&quot;)) { hanyupinyin.append(PinyinHelper.toHanyuPinyinStringArray(clChar, defaultFormat)[0]); // 如果字符不是中文,则不转换 } else { hanyupinyin.append(clChar); } } } catch (BadHanyuPinyinOutputFormatCombination e) { System.out.println(&quot;字符不能转成汉语拼音&quot;); } return hanyupinyin.toString(); } public static String getFirstLettersUp(String chineseLanguage) { return getFirstLetters(chineseLanguage, HanyuPinyinCaseType.UPPERCASE); } public static String getFirstLettersLo(String chineseLanguage) { return getFirstLetters(chineseLanguage, HanyuPinyinCaseType.LOWERCASE); } private static String getFirstLetters(String chineseLanguage, HanyuPinyinCaseType caseType) { char[] clChars = chineseLanguage.trim().toCharArray(); StringBuilder hanyupinyin = new StringBuilder(); HanyuPinyinOutputFormat defaultFormat = new HanyuPinyinOutputFormat(); // 输出拼音全部大写 defaultFormat.setCaseType(caseType); // 不带声调 defaultFormat.setToneType(HanyuPinyinToneType.WITHOUT_TONE); try { for (char clChar : clChars) { String str = String.valueOf(clChar); // 如果字符是中文,则将中文转为汉语拼音,并取第一个字母 if (str.matches(&quot;[\\u4e00-\\u9fa5]+&quot;)) { hanyupinyin.append(PinyinHelper.toHanyuPinyinStringArray(clChar, defaultFormat)[0].substring(0, 1)); // 如果字符是数字,取数字 } else if (str.matches(&quot;[0-9]+&quot;)) { hanyupinyin.append(clChar); // 如果字符是字母,取字母 } else if (str.matches(&quot;[a-zA-Z]+&quot;)) { hanyupinyin.append(clChar); //如果是标点符号的话，带着 } else {// 否则不转换 hanyupinyin.append(clChar); } } } catch (BadHanyuPinyinOutputFormatCombination e) { System.out.println(&quot;字符不能转成汉语拼音&quot;); } return hanyupinyin.toString(); } public static String getPinyinString(String chineseLanguage) { char[] clChars = chineseLanguage.trim().toCharArray(); StringBuilder hanyupinyin = new StringBuilder(); HanyuPinyinOutputFormat defaultFormat = new HanyuPinyinOutputFormat(); // 输出拼音全部大写 defaultFormat.setCaseType(HanyuPinyinCaseType.LOWERCASE); // 不带声调 defaultFormat.setToneType(HanyuPinyinToneType.WITHOUT_TONE); try { for (char clChar : clChars) { String str = String.valueOf(clChar); // 如果字符是中文,则将中文转为汉语拼音,并取第一个字母 if (str.matches(&quot;[\\u4e00-\\u9fa5]+&quot;)) { hanyupinyin.append(PinyinHelper.toHanyuPinyinStringArray( clChar, defaultFormat)[0]); // 如果字符是数字,取数字 } else if (str.matches(&quot;[0-9]+&quot;)) { // 如果字符是字母,取字母 hanyupinyin.append(clChar); } else if (str.matches(&quot;[a-zA-Z]+&quot;)) { hanyupinyin.append(clChar); } } } catch (BadHanyuPinyinOutputFormatCombination e) { System.out.println(&quot;字符不能转成汉语拼音&quot;); } return hanyupinyin.toString(); } /** * 取第一个汉字的第一个字符 */ public static String getFirstLetter(String chineseLanguage) { char[] clChars = chineseLanguage.trim().toCharArray(); String hanyupinyin = &quot;&quot;; HanyuPinyinOutputFormat defaultFormat = new HanyuPinyinOutputFormat(); // 输出拼音全部大写 defaultFormat.setCaseType(HanyuPinyinCaseType.UPPERCASE); // 不带声调 defaultFormat.setToneType(HanyuPinyinToneType.WITHOUT_TONE); try { String str = String.valueOf(clChars[0]); // 如果字符是中文,则将中文转为汉语拼音,并取第一个字母 if (str.matches(&quot;[\\u4e00-\\u9fa5]+&quot;)) { hanyupinyin = PinyinHelper.toHanyuPinyinStringArray( clChars[0], defaultFormat)[0].substring(0, 1); // 如果字符是数字,取数字 } else if (str.matches(&quot;[0-9]+&quot;)) { hanyupinyin += clChars[0]; // 如果字符是字母,取字母 } else if (str.matches(&quot;[a-zA-Z]+&quot;)) { hanyupinyin += clChars[0]; } } catch (BadHanyuPinyinOutputFormatCombination e) { System.out.println(&quot;字符不能转成汉语拼音&quot;); } return hanyupinyin; } // public static void main(String[] args) { // ChineseToPinyinUtil hanyuPinyinHelper = new ChineseToPinyinUtil(); // String city = ChineseToPinyinUtil.toHanyuPinyin(&quot;深圳市&quot;); // String string = &quot;shenzhen&quot;; // if (city.contains(string)) { // System.out.println(&quot;OK&quot;); // } // } }","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/tags/Java/"}]},{"title":"自定义Quartz超实用工具类","slug":"Quartz/自定义Quartz超实用工具类","date":"2017-11-17T03:09:37.000Z","updated":"2018-03-28T13:18:51.368Z","comments":true,"path":"2017/11/17/Quartz/自定义Quartz超实用工具类/","link":"","permalink":"https://blog.catalpaflat.cn/2017/11/17/Quartz/自定义Quartz超实用工具类/","excerpt":"","text":"自定义Quartz超实用工具类1.添加maven依赖 &lt;!-- https://mvnrepository.com/artifact/org.quartz-scheduler/quartz --&gt; &lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;${quartz.version}&lt;/version&gt; &lt;/dependency&gt; 2.实现Quartz实用工具类/** * Quartz任务调度器工具类 * * @author CatalpaFlat * @date Create in 10:25 2017/11/16 */ public class QuartzUtil { /** * 调度器工厂 */ private static SchedulerFactory schedulerFactory = new StdSchedulerFactory(); /** * 默认Job组名 */ private static String JOB_GROUP_NAME = &quot;DEFAULT_JOB_GROUP_NAME&quot;; /** * 默认触发器组名 */ private static String TRIGGER_GROUP_NAME = &quot;DEFAULT_TRIGGER_GROUP_NAME&quot;; /** * 获取调度器 * * @return Scheduler * @throws SchedulerException Scheduler获取异常 */ private static Scheduler getScheduler() throws SchedulerException { return schedulerFactory.getScheduler(); } /** * 获取CronTrigger * * @param jobName 任务名 * @param triggerGroupName 触发器组名（为空使用默认） * @param time crond格式时间 * @return CronTrigger */ private static CronTrigger getCronTrigger(String jobName, String triggerGroupName, String time) { if (StringUtils.isBlank(triggerGroupName)) { triggerGroupName = TRIGGER_GROUP_NAME; } return TriggerBuilder.newTrigger().withIdentity(jobName, triggerGroupName) .withSchedule(CronScheduleBuilder.cronSchedule(time)).build(); } /** * 获取JobDetail * * @param jobName 任务名 * @param jobGroupName 任务组名（为空使用默认） * @param cls 任务类 * @param jobDataMap 附带参数 * @return JobDetail */ private static JobDetail getJobDetail(String jobName, String jobGroupName, Class&lt;? extends Job&gt; cls, JobDataMap jobDataMap) { if (StringUtils.isBlank(jobGroupName)) { jobGroupName = JOB_GROUP_NAME; } if (jobDataMap != null) { return JobBuilder.newJob(cls).withIdentity(jobName, jobGroupName).usingJobData(jobDataMap).build(); } else { return JobBuilder.newJob(cls).withIdentity(jobName, jobGroupName).build(); } } /** * 设置JobDetail 和 CronTrigger 到 scheduler（已获取的调度器中，无需重复调用） * * @param cls 任务嘞 * @param jobName 任务名 * @param jobGroupName 任务组名（为空使用默认） * @param triggerGroupName 触发器组名（为空使用默认） * @param time crond格式时间 * @param jobDataMap 附带参数 * @param scheduler 调度器 * @return 设置成功与否 * @throws SchedulerException 调度器异常 */ private static boolean setJobDetailAndCronTriggerInScheduler(Class&lt;? extends Job&gt; cls, String jobName, String jobGroupName, String triggerGroupName, String time, JobDataMap jobDataMap, Scheduler scheduler) throws SchedulerException { if (!isJobKey(scheduler, jobName, jobGroupName)) { return false; } JobDetail jobDetail = getJobDetail(jobName, jobGroupName, cls, jobDataMap); CronTrigger trigger = getCronTrigger(jobName, triggerGroupName, time); scheduler.scheduleJob(jobDetail, trigger); if (!scheduler.isShutdown()) { scheduler.start(); } return true; } /** * 从调度器中移除Job * * @param scheduler 调度器 * @param triggerKey 触发器key（名，组） * @param jobKey 任务key（名，组） */ private static void removeJob(Scheduler scheduler, TriggerKey triggerKey, JobKey jobKey) { try { // 停止触发器 scheduler.pauseTrigger(triggerKey); //移除触发器 scheduler.unscheduleJob(triggerKey); // 删除任务 scheduler.deleteJob(jobKey); } catch (SchedulerException e) { e.printStackTrace(); } } /** * 使用CronTrigger类型添加任务 * * @param scheduler 调度器 * @param cls 任务嘞 * @param jobName 任务名 * @param jobGroupName 任务组名（为空使用默认） * @param triggerGroupName 触发器组名（为空使用默认） * @param time crond格式时间 * @param jobDataMap 附带参数 * @return 是否添加成功 */ private static boolean addJobByCronTrigger(Scheduler scheduler, Class&lt;? extends Job&gt; cls, String jobName, String jobGroupName, String triggerGroupName, String time, JobDataMap jobDataMap) { try { return setJobDetailAndCronTriggerInScheduler(cls, jobName, jobGroupName, triggerGroupName, time, jobDataMap, scheduler); } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 判断是否存在JobKey * * @param scheduler 任务调度器 * @param jobName 任务名 * @param jobGroupName 任务组名 * @return 是否存在JobKey */ private static boolean isJobKey(Scheduler scheduler, String jobName, String jobGroupName) { JobKey jobKey = JobKey.jobKey(jobName, jobGroupName); try { JobDetail jobDetail = scheduler.getJobDetail(jobKey); return jobDetail == null; } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 添加定时任务 * * @param cls 任务类 * @param jobName 任务名 * @param jobGroupName 任务组名（为空使用默认） * @param triggerGroupName 触发器组名（为空使用默认） * @param time crond格式时间 * @param jobDataMap 附带参数 * @return 是否正常添加任务 */ public static boolean addJobByCronTrigger(Class&lt;? extends Job&gt; cls, String jobName, String jobGroupName, String triggerGroupName, String time, JobDataMap jobDataMap) { try { if (StringUtils.isBlank(jobName)) { return false; } Scheduler scheduler = getScheduler(); return setJobDetailAndCronTriggerInScheduler(cls, jobName, jobGroupName, triggerGroupName, time, jobDataMap, scheduler); } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 修改任务时间 * * @param jobName 任务名 * @param time crond格式时间 * @param jobGroupName 任务组名（为空使用默认） * @param triggerGroupName 触发器组名（为空使用默认） * @param jobDataMap 附带参数 * @return 是否修改成功 */ public static boolean modifyJobTime(String jobName, String time, String jobGroupName, String triggerGroupName, JobDataMap jobDataMap) { try { if (StringUtils.isBlank(jobName)) { return false; } Scheduler scheduler = getScheduler(); if (StringUtils.isBlank(triggerGroupName)) { triggerGroupName = TRIGGER_GROUP_NAME; } TriggerKey triggerKey = TriggerKey.triggerKey(jobName, triggerGroupName); CronTrigger trigger = (CronTrigger) scheduler.getTrigger(triggerKey); if (trigger == null) { return false; } String oldTime = trigger.getCronExpression(); if (!oldTime.equalsIgnoreCase(time)) { if (StringUtils.isBlank(jobGroupName)) { jobGroupName = JOB_GROUP_NAME; } JobKey jobKey = JobKey.jobKey(jobName, jobGroupName); JobDetail jobDetail = scheduler.getJobDetail(jobKey); Class&lt;? extends Job&gt; jobClass = jobDetail.getJobClass(); removeJob(scheduler, triggerKey, jobKey); return addJobByCronTrigger(scheduler, jobClass, jobName, jobGroupName, triggerGroupName, time, jobDataMap); } return true; } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 启动所有定时任务 */ public static void startJobs() { try { Scheduler scheduler = getScheduler(); scheduler.start(); } catch (Exception e) { throw new RuntimeException(e); } } /** * 关闭所有定时任务 */ public static void shutdownJobs() { try { Scheduler scheduler = getScheduler(); if (!scheduler.isShutdown()) { scheduler.shutdown(); } } catch (Exception e) { throw new RuntimeException(e); } } /** * 停止一个job任务 * * @param jobName 任务名 * @param jobGroupName 任务组名（空位默认） * @return 是否停止 */ public static boolean pauseJob(String jobName, String jobGroupName) { try { Scheduler scheduler = getScheduler(); if (StringUtils.isBlank(jobGroupName)) { jobGroupName = JOB_GROUP_NAME; } scheduler.interrupt(JobKey.jobKey(jobName, jobGroupName)); return true; } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 恢复一个job任务 * * @param jobName 任务名 * @param jobGroupName 任务组名（空位默认） * @return 是否恢复 */ public static boolean resumeJob(String jobName, String jobGroupName) { try { Scheduler scheduler = getScheduler(); scheduler.resumeJob(JobKey.jobKey(jobName, jobGroupName)); return true; } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 添加定时任务 * * @param cls 任务类 * @param bJob 任务类属性 * @return 是否添加成功 */ public static boolean addJobByCronTrigger(Class&lt;? extends Job&gt; cls, BaseJob bJob) { if (bJob == null) { return false; } String jobName = bJob.getJobName(); if (StringUtils.isBlank(jobName)) { return false; } try { Scheduler scheduler = getScheduler(); return setJobDetailAndCronTriggerInScheduler(cls, jobName, bJob.getJobGroupName(), bJob.getTriggerGroupName(), bJob.getCronTime(), bJob.getJobDataMap(), scheduler); } catch (SchedulerException e) { e.printStackTrace(); return false; } } /** * 修改任务JobDateMap * * @param cls 任务类 * @param bJob 任务类属性 * @return 是否修改成功 */ public static boolean modifyJobDateMap(Class&lt;? extends Job&gt; cls, BaseJob bJob) { if (bJob == null) { return false; } String jobName = bJob.getJobName(); if (StringUtils.isBlank(jobName)) { return false; } String triggerGroupName = bJob.getTriggerGroupName(); if (StringUtils.isBlank(triggerGroupName)) { triggerGroupName = TRIGGER_GROUP_NAME; } TriggerKey triggerKey = TriggerKey.triggerKey(jobName, triggerGroupName); String jobGroupName = bJob.getJobGroupName(); if (StringUtils.isBlank(jobGroupName)) { jobGroupName = JOB_GROUP_NAME; } try { Scheduler scheduler = getScheduler(); JobKey jobKey = JobKey.jobKey(jobName, jobGroupName); JobDetail jobDetail1 = scheduler.getJobDetail(jobKey); if (jobDetail1 == null) { return false; } JobDataMap oldJobDataMap = jobDetail1.getJobDataMap(); JobDataMap jobDataMap = bJob.getJobDataMap(); if (!oldJobDataMap.equals(jobDataMap)) { Class&lt;? extends Job&gt; jobClass = jobDetail1.getJobClass(); removeJob(scheduler, triggerKey, jobKey); return addJobByCronTrigger(scheduler, jobClass, jobName, jobGroupName, triggerGroupName, bJob.getCronTime(), jobDataMap); } return true; } catch (SchedulerException e) { e.printStackTrace(); return false; } } }","categories":[{"name":"Quartz","slug":"Quartz","permalink":"https://blog.catalpaflat.cn/categories/Quartz/"}],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"https://blog.catalpaflat.cn/tags/Quartz/"}]},{"title":"深入解读Quartz任务调度器","slug":"Quartz/深入解读Quartz任务调度器","date":"2017-11-15T09:24:17.000Z","updated":"2018-03-28T13:18:13.215Z","comments":true,"path":"2017/11/15/Quartz/深入解读Quartz任务调度器/","link":"","permalink":"https://blog.catalpaflat.cn/2017/11/15/Quartz/深入解读Quartz任务调度器/","excerpt":"","text":"深入解读Quartz任务调度器1.Quartz简介1.1.概要 Quartz是OpenSymphony提供的强大的开源任务调度框架。 官网：http://www.quartz-scheduler.org 纯Java实现，精细控制排程。 1.2.Quartz特点 强大的调度能力 灵活的应用方式 强大的分布式和集群能力1.3.Quartz设计模式 Builder模式 组件模式 Factory模式 链式写法1.4.Quartz体系结构1.4.1.三大核心 调度器 任务 触发器 1.4.2.重要组成1）任务： Job：表示一个工作，要执行的具体内容。此接口中只有一个方法。要创建一个任务，必须得实现这个接口。该接口只有一个execute方法，任务每次被调用的时候都会执行这个execute方法的逻辑，类似TimerTask的run方法，在里面编写业务逻辑。 public class TestJob implements Job { /**把要执行的操作，写在execute方法中 */ @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException { SimpleDateFormat sdf = new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;); System.out.println(&quot;I can do something...&quot;); System.out.println(sdf.format(new Date())); } } 生命周期：在每次调度器执行job时，它在调用execute方法前会创建一个新的job实例，当调用完成之后，关联的job对象实例会被释放，释放的实例会被垃圾回收机制回收。 JobBuilder：可向任务传递数据,通常情况下,我们使用它就可向任务类发送数据了，如有特别复杂的传递参数,它提供了一个传递递:JobDataMap对象的方法 JobDetail jobDetail = JobBuilder.newJob(TestJob.class).withIdentity(&quot;testJob&quot;,&quot;group1&quot;).build(); JobDetail：用来保存我们任务的详细信息。一个JobDetail可以有多个Trigger，但是一个Trigger只能对应一个JobDetail。下面是JobDetail的一些常用的属性和含义： JobStore：负责跟踪所有你给scheduler的“工作数据”：jobs, triggers, calendars, 等。 RAMJobStore：是使用最简单的也是最高效(依据CPU时间)的JobStore 。RAMJobStore 正如它名字描述的一样，它保存数据在RAM。缺点是你的应用结束之后所有的数据也丢失了–这意味着RAMJobStore 不具有保持job和trigger持久的能力。对于一些程序是可以接受的，甚至是期望的，但对于其他的程序可能是灾难性的。使用RAMJobStore配置Quartz：配置如下 org.quartz.jobStore.class = org.quartz.simpl.RAMJobStore JDBCJobStore：以JDBC的方式保存数据在数据库中。它比RAMJobStore的配置复杂一点，也没有RAMJobStore快。然而,性能缺点不是糟透了,特别是如果你在数据库表主键上建立了索引。在机器之间的LAN(在scheduler 和数据库之间)合理的情况下，检索和更新一个被触发的Trigger花费的时间少于10毫秒。几乎适用于所有的数据库，广泛用于 Oracle。PostgreSQL, MySQL, MS SQLServer, HSQLDB, 和DB2。使用JDBCJobStore之前你必须首先创建一系列Quartz要使用的表。你可以发现表创建语句在Quartz发布目录的 “docs/dbTables”下面。你需要确定你的应用要使用的事务类型。如果你不想绑定调度命令(例如增加和移除Trigger)到其他的事务，你可以使用JobStoreTX (最常用的选择)作为你的Jobstore。如果你需要Quartz和其他的事务(例如在J2EE应用服务器中)一起工作，你应该使用JobStoreCMT ，Quartz 将让应用服务器容器管理这个事务。使用JobStoreTx配置Quartz： org.quartz.jobStore.class = org.quartz.impl.jdbcjobstore.JobStoreTX org.quartz.jobStore.driverDelegateClass = org.quartz.impl.jdbcjobstore.StdJDBCDelegate #配置表的前缀 org.quartz.jobStore.tablePrefix = QRTZ_ #使用JNDI数据源的时候，数据源的名字 org.quartz.jobStore.dataSource = myDS TerracottaJobStore：提供了一个方法：在不使用数据库的情况下使它具有收缩性和强壮性。可以是集群的也可以是非集群的，在这两种情况下为你的job数据提供了一个存储机制用于应用程序重启之间持久,因为数据是存储在Terracotta服务器。它的性能比使用数据库访问JDBCJobStore好一点儿(大约是一个数量级)，但是明显比RAMJobStore慢。使用TerracottaJobStore配置Quartz： org.quartz.jobStore.class = org.terracotta.quartz.TerracottaJobStore org.quartz.jobStore.tcConfigUrl = localhost:9510 JobDataMap：中可以包含不限量的（序列化的）数据对象，在job实例执行的时候，可以使用其中的数据；JobDataMap是Java Map接口的一个实现，额外增加了一些便于存取基本类型的数据的方法。 存： JobDetail jobDetail = JobBuilder.newJob(TestJob.class).withIdentity(&quot;testJob&quot;,&quot;group1&quot;).usingJobData(&quot;date1&quot;,&quot;存内容&quot;).build(); 取： public class TestJob implements Job { /**把要执行的操作，写在execute方法中 */ @Override public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException { JobKey key = jobExecutionContext.getJobDetail().getKey(); JobDataMap jobDataMap = jobExecutionContext.getJobDetail().getJobDataMap(); String date1 = jobDataMap.getString(&quot;date1&quot;); } } 2）触发器：用来触发执行Job 2.1）触发器通用属性： Jobkey：表示job实例的标识，触发器被触发时，该指定的job实例会被执行 StartTime：表示触发器的时间表首次被触发的时间，它的值类型为：java.util.Date EndTime：指定触发器的不再被触发的时间，它的值类型为：java.util.Date 2.2）触发器类型： SimpleTrigger： 主要是针对一些相对简单的时间触发进行配置使用，比如在指定的时间开始然后在一定的时间间隔之内重复执行一个Job，同时可以任意指定重复的次数。下面就是使用一个SimpleTrigger的例子: //创建触发器 每3秒钟执行一次(无开始时间和结束时间) Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;trigger1&quot;, &quot;group3&quot;) .withSchedule( SimpleScheduleBuilder.simpleSchedule() .withIntervalInSeconds(3).repeatForever()).build(); //创建触发器 每3秒钟执行一次(有开始时间和结束时间) long now = new Date().getTime(); Date start = new Date(now+6000); Date end = new Date(now+12000); //创建触发器 每3秒钟执行一次 Trigger trigger = TriggerBuilder.newTrigger() .withIdentity(&quot;trigger1&quot;, &quot;group3&quot;) .startAt(start) .endAt(end) .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInSeconds(3).repeatForever()).build(); SimpleTrigger具有丰富的构造函数，根据业务需求构造不同的构造函数。 CronTrigger： 可以配置更复杂的触发时刻表，基于日历的作业触发器，而不像SimpleTrigger那样精确指定间隔时间，比SimpleTrigger更加常用。 Cron表达式：用于配置CronTrigger实例，是由7个表达式组成的字符串，描述了时间表的详细信息。 格式为：[秒][分][时][日][月][周][年] Cron表达式特殊字符意义对应表： 通配符说明： Cron表达式例子： TriggerBuilder.newTrigger().withIdentity(&quot;trigger2&quot;,&quot;group2&quot;) .withSchedule(CronScheduleBuilder.cronSchedule(&quot;0 0 9 ? * 6L *&quot;)).build(); Cron表达式小技巧： 1. ‘L’和‘W’可以一起组合使用 2. 周字段英文字母不区分大小写即MOM与mom相同 3. 利用工具，在线生成cron表达式：http://cron.qqe2.com/ NthIncludedDayTrigger：是 Quartz 开发团队最新加入到框架中的一个 Trigger。它设计用于在每一间隔类型的第几天执行 Job。例如，你要在每个月的 15 号执行开票的 Job，用 NthIncludedDayTrigger就再合适不过了。 NthIncludedDayTrigger trigger = new NthIncludedDayTrigger(&quot;NthIncludedDayTrigger&quot;,Scheduler.DEFAULT_GROUP); trigger.setN(15); trigger.setIntervalType(NthIncludedDayTrigger.INTERVAL_TYPE_MONTHLY); 3）调度器Scheduler 代表一个Quartz的独立运行容器，Trigger和JobDetail可以注册到Scheduler中，两者在Scheduler中拥有各自的组及名称，组及名称是Scheduler查找定位容器中某一对象的依据，Trigger的组及名称必须唯一，JobDetail的组和名称也必须唯一（但可以和Trigger的组和名称相同，因为它们是不同类型的）。Scheduler定义了多个接口方法，允许外部通过组及名称访问和控制容器中Trigger和JobDetail。 Scheduler可以将Trigger绑定到某一JobDetail中，这样当Trigger触发时，对应的Job就被执行。一个Job可以对应多个Trigger，但一个Trigger只能对应一个Job。 可以通过SchedulerFactory创建一个Scheduler实例。Scheduler拥有一个SchedulerContext，它类似于ServletContext，保存着Scheduler上下文信息，Job和Trigger都可以访问SchedulerContext内的信息。SchedulerContext内部通过一个Map，以键值对的方式维护这些上下文数据，SchedulerContext为保存和获取数据提供了多个put()和getXxx()的方法。可以通过Scheduler# getContext()获取对应的SchedulerContext实例； SchedulerFactory schedulerfactory=new StdSchedulerFactory(); Scheduler scheduler = schedulerfactory.getScheduler(); DirectSchedulerFactory factory = DirectSchedulerFactory.getInstance(); try { Scheduler scheduler = factory.getScheduler(); } catch (SchedulerException e) { e.printStackTrace(); } 4)SchedulerFactory: 使用一组参数（java.util.Properties）来创建和出书啊Quartz调度器 配置参数一般存储在quartz.properties中 调用getScheduler方法就能创建和初始化调度器 5)quartz.properties:Quartz-Job的quartz.properties配置文件说明，此文件在quartz的jar包有，可直接拿过来使用不过只有基本的几个配置 自己可根据需要进行扩充；另外如果项目中没有对该配置文件重写，则Quartz会加载自己jar包中的quartz.properties文件。 # Default Properties file for use by StdSchedulerFactory # to create a Quartz Scheduler Instance, if a different # properties file is not explicitly specified. # # =========================================================================== # Configure Main Scheduler Properties 调度器属性 # =========================================================================== org.quartz.scheduler.instanceName: DefaultQuartzScheduler #org.quartz.scheduler.instanceid:AUTO org.quartz.scheduler.rmi.export: false org.quartz.scheduler.rmi.proxy: false org.quartz.scheduler.wrapJobExecutionInUserTransaction: false # =========================================================================== # Configure ThreadPool 线程池属性 # =========================================================================== #线程池的实现类（一般使用SimpleThreadPool即可满足几乎所有用户的需求） org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool #指定线程数，至少为1（无默认值）(一般设置为1-100直接的整数合适) org.quartz.threadPool.threadCount: 10 #设置线程的优先级（最大为java.lang.Thread.MAX_PRIORITY 10，最小为Thread.MIN_PRIORITY 1，默认为5） org.quartz.threadPool.threadPriority: 5 #设置SimpleThreadPool的一些属性 #设置是否为守护线程 #org.quartz.threadpool.makethreadsdaemons = false #org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true #org.quartz.threadpool.threadsinheritgroupofinitializingthread=false #线程前缀默认值是：[Scheduler Name]_Worker #org.quartz.threadpool.threadnameprefix=swhJobThead; # 配置全局监听(TriggerListener,JobListener) 则应用程序可以接收和执行 预定的事件通知 # =========================================================================== # Configuring a Global TriggerListener 配置全局的Trigger监听器 # MyTriggerListenerClass 类必须有一个无参数的构造函数，和 属性的set方法，目前2.2.x只支持原始数据类型的值（包括字符串） # =========================================================================== #org.quartz.triggerListener.NAME.class = com.swh.MyTriggerListenerClass #org.quartz.triggerListener.NAME.propName = propValue #org.quartz.triggerListener.NAME.prop2Name = prop2Value # =========================================================================== # Configuring a Global JobListener 配置全局的Job监听器 # MyJobListenerClass 类必须有一个无参数的构造函数，和 属性的set方法，目前2.2.x只支持原始数据类型的值（包括字符串） # =========================================================================== #org.quartz.jobListener.NAME.class = com.swh.MyJobListenerClass #org.quartz.jobListener.NAME.propName = propValue #org.quartz.jobListener.NAME.prop2Name = prop2Value # =========================================================================== # Configure JobStore 存储调度信息（工作，触发器和日历等） # =========================================================================== # 信息保存时间 默认值60秒 org.quartz.jobStore.misfireThreshold: 60000 #保存job和Trigger的状态信息到内存中的类 org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore # =========================================================================== # Configure SchedulerPlugins 插件属性 配置 # =========================================================================== # 自定义插件 #org.quartz.plugin.NAME.class = com.swh.MyPluginClass #org.quartz.plugin.NAME.propName = propValue #org.quartz.plugin.NAME.prop2Name = prop2Value #配置trigger执行历史日志（可以看到类的文档和参数列表） org.quartz.plugin.triggHistory.class = org.quartz.plugins.history.LoggingTriggerHistoryPlugin org.quartz.plugin.triggHistory.triggerFiredMessage = Trigger {1}.{0} fired job {6}.{5} at: {4, date, HH:mm:ss MM/dd/yyyy} org.quartz.plugin.triggHistory.triggerCompleteMessage = Trigger {1}.{0} completed firing job {6}.{5} at {4, date, HH:mm:ss MM/dd/yyyy} with resulting trigger instruction code: {9} #配置job调度插件 quartz_jobs(jobs and triggers内容)的XML文档 #加载 Job 和 Trigger 信息的类 （1.8之前用：org.quartz.plugins.xml.JobInitializationPlugin） org.quartz.plugin.jobInitializer.class = org.quartz.plugins.xml.XMLSchedulingDataProcessorPlugin #指定存放调度器(Job 和 Trigger)信息的xml文件，默认是classpath下quartz_jobs.xml org.quartz.plugin.jobInitializer.fileNames = my_quartz_job2.xml #org.quartz.plugin.jobInitializer.overWriteExistingJobs = false org.quartz.plugin.jobInitializer.failOnFileNotFound = true #自动扫描任务单并发现改动的时间间隔,单位为秒 org.quartz.plugin.jobInitializer.scanInterval = 10 #覆盖任务调度器中同名的jobDetail,避免只修改了CronExpression所造成的不能重新生效情况 org.quartz.plugin.jobInitializer.wrapInUserTransaction = false # =========================================================================== # Sample configuration of ShutdownHookPlugin ShutdownHookPlugin插件的配置样例 # =========================================================================== #org.quartz.plugin.shutdownhook.class = \\org.quartz.plugins.management.ShutdownHookPlugin #org.quartz.plugin.shutdownhook.cleanShutdown = true # # Configure RMI Settings 远程服务调用配置 # #如果你想quartz-scheduler出口本身通过RMI作为服务器，然后设置“出口”标志true(默认值为false)。 #org.quartz.scheduler.rmi.export = false #主机上rmi注册表(默认值localhost) #org.quartz.scheduler.rmi.registryhost = localhost #注册监听端口号（默认值1099） #org.quartz.scheduler.rmi.registryport = 1099 #创建rmi注册，false/never：如果你已经有一个在运行或不想进行创建注册 # true/as_needed:第一次尝试使用现有的注册，然后再回来进行创建 # always:先进行创建一个注册，然后再使用回来使用注册 #org.quartz.scheduler.rmi.createregistry = never #Quartz Scheduler服务端端口，默认是随机分配RMI注册表 #org.quartz.scheduler.rmi.serverport = 1098 #true:链接远程服务调度(客户端),这个也要指定registryhost和registryport，默认为false # 如果export和proxy同时指定为true，则export的设置将被忽略 #org.quartz.scheduler.rmi.proxy = false","categories":[{"name":"Quartz","slug":"Quartz","permalink":"https://blog.catalpaflat.cn/categories/Quartz/"}],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"https://blog.catalpaflat.cn/tags/Quartz/"}]},{"title":"消息队列之RabbitMQ","slug":"消息队列/RabbitMQ","date":"2017-11-11T08:08:34.000Z","updated":"2018-03-28T13:04:44.337Z","comments":true,"path":"2017/11/11/消息队列/RabbitMQ/","link":"","permalink":"https://blog.catalpaflat.cn/2017/11/11/消息队列/RabbitMQ/","excerpt":"","text":"RabbitMQ1.RabbitMQ概述&emsp;&emsp;MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。应用程序通过读写出入队列的消息（针对应用程序的数据）来通信，而无需专用连接来链接它们。消息传递指的是程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术。排队指的是应用程序通过 队列来通信。队列的使用除去了接收和发送应用程序同时执行的要求。其中较为成熟的MQ产品有IBM WEBSPHERE MQ等等。 2.RabbitMQ安装Windows环境下：RabbitMQ基于erlang，因此先安装erlang2.1 安装erlang2.1.1 下载并安装erlangerlang下载地址：http://www.erlang.org/downloadserlang安装过程直接一直next到底2.1.2 设置erlang环境变量将;%ERLANG_HOME%\\bin添加到Path2.1.3 测试erlang是否安装成功2.2 安装RabbitMQ2.2.1 下载并安装RabbitMQRabbitMQ下载地址：http://www.rabbitmq.com/install-windows.htmlRabbitMQ安装过程也一直next到底2.2.2 激活 RabbitMQ’s Management Plugin到RabbitMQ的安装目录找到E:\\RabbitMQServer\\rabbitmq_server-3.6.5\\sbin\\运行rabbitmq-plugins enable rabbitmq_management接着直接重启服务rabbitmq-service stoprabbitmq-service start2.2.3 浏览器访问http://localhost:15672/#/使用账号：guest密码：guest登录即可自此RabbitMQ安装完毕","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.catalpaflat.cn/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.catalpaflat.cn/tags/消息队列/"}]},{"title":"Java 自定义超实用Redis工具类（满足对象，list，map等类型）","slug":"java/Java 自定义超实用Redis工具类（满足对象，list，map等类型）","date":"2017-11-11T07:11:22.000Z","updated":"2018-03-28T12:59:07.739Z","comments":true,"path":"2017/11/11/java/Java 自定义超实用Redis工具类（满足对象，list，map等类型）/","link":"","permalink":"https://blog.catalpaflat.cn/2017/11/11/java/Java 自定义超实用Redis工具类（满足对象，list，map等类型）/","excerpt":"","text":"自定义超实用Redis工具类（满足对象，list，map等类型）该工具类，可以存储对象、list，map等各种数据类型到Redis中，大大有效提高开发效率。 1.添加maven依赖&lt;!--序列化工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.objenesis&lt;/groupId&gt; &lt;artifactId&gt;objenesis&lt;/artifactId&gt; &lt;version&gt;${objenesis.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.dyuproject.protostuff/protostuff-core --&gt; &lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;${dyuproject.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dyuproject.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;${dyuproject.version}&lt;/version&gt; &lt;/dependency&gt; 注：采用序列化工具进行解析。版本如下： &lt;dyuproject.version&gt;1.1.3&lt;/dyuproject.version&gt; &lt;objenesis.version&gt;2.6&lt;/objenesis.version&gt; 2.序列化工具类/** * 序列化工具类 * @Author： CatalpaFlat * @Descrition: * @Date: Create in 15:04 2017/11/11 * @Modified BY： */ public class ProtoStuffSerializerUtil { public static &lt;T&gt; byte[] serialize(T obj) { if (obj == null) { throw new RuntimeException(&quot;序列化对象(&quot; + obj + &quot;)!&quot;); } @SuppressWarnings(&quot;unchecked&quot;) Schema&lt;T&gt; schema = (Schema&lt;T&gt;) RuntimeSchema.getSchema(obj.getClass()); LinkedBuffer buffer = LinkedBuffer.allocate(1024 * 1024); byte[] protostuff = null; try { protostuff = ProtostuffIOUtil.toByteArray(obj, schema, buffer); } catch (Exception e) { throw new RuntimeException(&quot;序列化(&quot; + obj.getClass() + &quot;)对象(&quot; + obj + &quot;)发生异常!&quot;, e); } finally { buffer.clear(); } return protostuff; } public static &lt;T&gt; T deserialize(byte[] paramArrayOfByte, Class&lt;T&gt; targetClass) { if (paramArrayOfByte == null || paramArrayOfByte.length == 0) { throw new RuntimeException(&quot;反序列化对象发生异常,byte序列为空!&quot;); } T instance = null; try { // T message = objenesis.newInstance(cls); instance = targetClass.newInstance(); } catch (InstantiationException | IllegalAccessException e) { throw new RuntimeException(&quot;反序列化过程中依据类型创建对象失败!&quot;, e); } Schema&lt;T&gt; schema = RuntimeSchema.getSchema(targetClass); ProtostuffIOUtil.mergeFrom(paramArrayOfByte, instance, schema); return instance; } public static &lt;T&gt; byte[] serializeList(List&lt;T&gt; objList) { if (objList == null || objList.isEmpty()) { throw new RuntimeException(&quot;序列化对象列表(&quot; + objList + &quot;)参数异常!&quot;); } @SuppressWarnings(&quot;unchecked&quot;) Schema&lt;T&gt; schema = (Schema&lt;T&gt;) RuntimeSchema.getSchema(objList.get(0).getClass()); LinkedBuffer buffer = LinkedBuffer.allocate(1024 * 1024); byte[] protostuff = null; ByteArrayOutputStream bos = null; try { bos = new ByteArrayOutputStream(); ProtostuffIOUtil.writeListTo(bos, objList, schema, buffer); protostuff = bos.toByteArray(); } catch (Exception e) { throw new RuntimeException(&quot;序列化对象列表(&quot; + objList + &quot;)发生异常!&quot;, e); } finally { buffer.clear(); try { if(bos!=null){ bos.close(); } } catch (IOException e) { e.printStackTrace(); } } return protostuff; } public static &lt;T&gt; List&lt;T&gt; deserializeList(byte[] paramArrayOfByte, Class&lt;T&gt; targetClass) { if (paramArrayOfByte == null || paramArrayOfByte.length == 0) { throw new RuntimeException(&quot;反序列化对象发生异常,byte序列为空!&quot;); } Schema&lt;T&gt; schema = RuntimeSchema.getSchema(targetClass); List&lt;T&gt; result = null; try { result = ProtostuffIOUtil.parseListFrom(new ByteArrayInputStream(paramArrayOfByte), schema); } catch (IOException e) { throw new RuntimeException(&quot;反序列化对象列表发生异常!&quot;,e); } return result; } public static class Person{ int id; String name; public Person(){ } public Person(int id, String name){ this.id = id; this.name = name; } public int getId() { return id; } public String getName() { return name; } } } 3.配置redisConfig类进行存储/** * redis配置类 * @Author： CatalpaFlat * @Descrition: * @Date: Create in 15:04 2017/11/11 * @Modified BY： */ @Component public class RedisConfig { public final static String CAHCENAME = &quot;CatalpaFlat&quot;;// 缓存名 public final static int CAHCETIME = 60;// 默认缓存时间 60S public final static int CAHCEHOUR = 60 * 60;// 默认缓存时间 1hr public final static int CAHCEDAY = 60 * 60 * 24;// 默认缓存时间 1Day public final static int CAHCEWEEK = 60 * 60 * 24 * 7;// 默认缓存时间 1week public final static int CAHCEMONTH = 60 * 60 * 24 * 7 * 30;// 默认缓存时间 1month public final static int CAHCEYEAR = 60 * 60 * 24 * 7 * 30 * 12;// 默认缓存时间 1年 @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; public &lt;T&gt; boolean putCache(String key, T obj) { final byte[] bkey = key.getBytes(); final byte[] bvalue = ProtoStuffSerializerUtil.serialize(obj); boolean result = redisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; connection.setNX(bkey, bvalue)); return result; } public &lt;T&gt; void putCacheWithExpireTime(String key, T obj, final long expireTime) { final byte[] bkey = key.getBytes(); final byte[] bvalue = ProtoStuffSerializerUtil.serialize(obj); redisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; { connection.setEx(bkey, expireTime, bvalue); return true; }); } public &lt;T&gt; boolean putListCache(String key, List&lt;T&gt; objList) { final byte[] bkey = key.getBytes(); final byte[] bvalue = ProtoStuffSerializerUtil.serializeList(objList); boolean result = redisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; connection.setNX(bkey, bvalue)); return result; } public &lt;T&gt; boolean putListCacheWithExpireTime(String key, List&lt;T&gt; objList, final long expireTime) { final byte[] bkey = key.getBytes(); final byte[] bvalue = ProtoStuffSerializerUtil.serializeList(objList); boolean result = redisTemplate.execute((RedisCallback&lt;Boolean&gt;) connection -&gt; { connection.setEx(bkey, expireTime, bvalue); return true; }); return result; } public &lt;T&gt; T getCache(final String key, Class&lt;T&gt; targetClass) { byte[] result = redisTemplate.execute(new RedisCallback&lt;byte[]&gt;() { @Override public byte[] doInRedis(RedisConnection connection) throws DataAccessException { return connection.get(key.getBytes()); } }); if (result == null) { return null; } return ProtoStuffSerializerUtil.deserialize(result, targetClass); } public &lt;T&gt; List&lt;T&gt; getListCache(final String key, Class&lt;T&gt; targetClass) { byte[] result = redisTemplate.execute(new RedisCallback&lt;byte[]&gt;() { @Override public byte[] doInRedis(RedisConnection connection) throws DataAccessException { return connection.get(key.getBytes()); } }); if (result == null) { return null; } return ProtoStuffSerializerUtil.deserializeList(result, targetClass); } /** * 精确删除key * * @param key */ public void deleteCache(String key) { redisTemplate.delete(key); } /** * 模糊删除key * * @param pattern */ public void deleteCacheWithPattern(String pattern) { Set&lt;String&gt; keys = redisTemplate.keys(pattern); redisTemplate.delete(keys); } /** * 清空所有缓存 */ public void clearCache() { deleteCacheWithPattern(RedisConfig.CAHCENAME + &quot;|*&quot;); } } 4.测试序列化工具类注：基于这篇文章http://blog.csdn.net/DuShiWoDeCuo/article/details/78506579 /** * @Author： CatalpaFlat * @Descrition: * @Date: Create in 10:08 2017/11/8 * @Modified BY： */ @RunWith(SpringRunner.class) @ContextConfiguration({&quot;classpath:spring/*.xml&quot;}) public class TestRedis { @Resource private RedisConfig redisConfig; @Autowired(required=true) private RedisKeyUtil redisKeyUtil; @Autowired private RedisTemplate redisTemplate; private static final Logger log = Logger.getLogger(TestRedis.class.getName()); @Test public void test(){ // redisTemplate.opsForValue().set(&quot;chen&quot;, &quot;陈梓平&quot;); // log.info(&quot;value：&quot;+redisTemplate.opsForValue().get(&quot;chen&quot;)); String key = redisKeyUtil.getSystemRedisKeyDistribution(&quot;Test&quot;, this.getClass().getName(), &quot;test&quot;); log.info(&quot;cache-key:&quot;+key); redisConfig.putCache(key,&quot;测试链接&quot;); String cache = redisConfig.getCache(key, String.class); log.info(&quot;cache-value:&quot;+cache); } }","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/tags/Java/"}]},{"title":"Nginx配置多虚拟主机（即配置域名）","slug":"nginx/Nginx配置多虚拟主机（即配置域名）","date":"2017-08-27T13:33:54.000Z","updated":"2018-03-28T13:14:04.431Z","comments":true,"path":"2017/08/27/nginx/Nginx配置多虚拟主机（即配置域名）/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/27/nginx/Nginx配置多虚拟主机（即配置域名）/","excerpt":"","text":"Nginx配置多虚拟主机（即配置域名）1.存放站点（即项目）站点的根目录和域名相同 1.1.创建a域名存放地址1mkdir -p /data/site/a.chen.com 1.2.创建a域名的首页123cd /data/site/a.chen.comtouch inde.htmlecho &apos;this is a from chen com...&apos; &gt; /data/site/a.chen.com/inde.html 1.3.创建b域名存放地址1mkdir -p /data/site/b.chen.com 1.4.创建b域名的首页123cd /data/site/b.chen.comtouch inde.htmlecho &apos;this is b from chen com...&apos; &gt; /data/site/b.chen.com/inde.html 1.5.添加日志存放目录1mkdir -p /data/logs/nginx 2.配置nginx的配置文件（注：若还没安装nginx的话，详情请看这一篇文章 http://blog.csdn.net/dushiwodecuo/article/details/78393454） 2.1.进入nginx配置目录1cd /usr/local/nginx/conf/ 2.2.编辑nginx.conf1vim nginx.conf 2.2.1.配置nginx日志格式在nginx.conf中找到如下内容，并且将#注释标志去掉123#log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;# &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;# &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; 2.2.2.配置nginx主配置内容a域名服务器123456789server&#123; server_name a.chen.com; listen 80; root /data/site/a.chen.com; access_log /data/logs/nginx/a.chen.com-access.log main; location / &#123; &#125;&#125; b域名服务器123456789server&#123; server_name b.chen.com; listen 80; root /data/site/b.chen.com; access_log /data/logs/nginx/b.chen.com-access.log main; location / &#123; &#125;&#125; 配置解析： server{}：配置虚拟主机必须有的的段 server_name:虚拟主机的域名，可以写多个域名，类似于别名，比如说你可以配置成：（这样的话，任何一个域名，内容都是一样的） 1server_name a.chen.com b.chen.com c.chen.com listen：127.0.0.1:80 监听端口 root ：站点根目录，网站文件存放的地方。（注：站点目录和域名尽量一样） access_log：访问日志 location /{}：默认uri 3.检查nginx配置是否正确1/usr/local/nginx/sbin/nginx -t 若出现以下两行ok和successful，表示配置没问题12nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 4.重启nginx1/usr/local/nginx/sbin/nginx -s reload （注：若是之前没有启动过，则启动即可，但若启动过了，应该重启，不然会出现后面配置成功后但是访问域名却一直是nginx的欢迎界面）5.测试5.1.Windows下测试修改hosts文件：C:\\Windows\\System32\\drivers\\etc，添加以下内容：12192.168.1.111 a.chen.com192.168.1.111 b.chen.com 5.2.Linux下测试修改hosts文件1echo &apos;192.168.1.111 a.chen.com 192.168.1.111 b.chen.com&apos; &gt;&gt; /etc/hosts 5.3.测试结果浏览器直接输入：a.chen.com 和 b.chen.comLinux测试：1curl http://a.chen.com","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"Nginx root&alias文件路径配置解析","slug":"nginx/Nginx root&alias文件路径配置解析","date":"2017-08-26T14:43:43.000Z","updated":"2018-03-28T13:14:10.596Z","comments":true,"path":"2017/08/26/nginx/Nginx root&alias文件路径配置解析/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/26/nginx/Nginx root&alias文件路径配置解析/","excerpt":"","text":"Nginx root&amp;alias文件路径配置解析 nginx在指定文件路径有两种方式root和alias，这两种的主要区别在于nginx如何解析location后面的uri，这会使两者分别以不同的方式请求映射到服务器的文件上。1.root语法的使用【root】语法： root path默认值： root html配置段： http/server/location/if例子:123456location ^~/chen/ &#123; root /data/www/www.chen.com; autoindex on; auto_basic &quot;Restricted&quot;; auto_basic_user_file passwd/chen;&#125; 例子解析：&emsp;&emsp;如果请求的uri是/chen/httplogs/www.chen.com-access.log时，web服务器将会返回服务器上的“/data/www/www.chen.com”(root的path)+“/chen/httplogs/www.chen.com-access.log”的文件。也就是说root路径配置会根据完整的uri请求来映射，也就是/path/uri 2.alias语法的使用【alias】语法：alias path配置段：location例子:123456location ^~ /binapp/ &#123; limit_conn limit 4; limit_rate 200k; internal; alias /data/statics/bin/apps/;&#125; 例子解析：&emsp;&emsp;alias会把location后面配置的路径丢弃，把当前匹配到的目录指向到指定的目录。如果一个请求的uri是/binapp/a.chen.com/favicon时，web服务器将会返回服务器上的“/data/statics/bin/apps/”+“a.chen.com/favicon.html”的文件&emsp;&emsp;alias使用总结： 使用alias时，目录名后面一定要加“/“ alias可以指定任何名称 alias在使用正则表达式时，必须捕捉要匹配到的内容并在指定的内容处使用 alias只能位于location块中。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"Nginx rewrite深入解读","slug":"nginx/Nginx rewrite深入解读","date":"2017-08-26T10:23:12.000Z","updated":"2018-03-28T13:12:50.203Z","comments":true,"path":"2017/08/26/nginx/Nginx rewrite深入解读/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/26/nginx/Nginx rewrite深入解读/","excerpt":"","text":"Nginx rewrite深入解读1.什么是rewrite官方解读：nginx的重写模块（rewrite）是一个简单的正则表达式匹配与一个虚拟堆叠机结合。个人解读：nginx的rewrite是结合正则表达式和标志位实现url重写、改变以及重定向。如：域名跳转，防盗链，反向代理，各种跳转（跳转维护界面，前端跳转，基于uri跳转，基于目录跳转等） 2.rewrite的支撑源头nginx通过ngx_http_rewrite_module模块支持url重写、支持if条件判断。依赖于PCRE库，因此需要安装pcre。 3.rewrite的7个指令3.1.break 语法：break 默认值：none 配置段：server,location,if 作用：完成当前设置的重写规则，停止处理后续rewrite指令集，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行。 实例：1234if ($slow) &#123; limit_rate 10k; break;&#125; 3.2.if 语法：if(condition){…} 默认值：none 配置段：server,location 作用：对给定的条件condition进行判断 conditon：if条件(conditon)可以是如下任何内容: 一个变量名:空字符传“ ”或者一些“0”开始的字符串为false 字符串比较：使用=或!=运算符 正则表达式匹配：用~或~*+正则表达式匹配的变量，如果这个正则表达式中包含}或;，则整个表达式需要用” 或’ 包围 文件是否存在：使用-f或者!-f操作符 目录是否存在：使用-d或者!-d操作符 文件、目录、符号链接是否存在：使用-e或者!-e操作符 文件是否可执行：使用-x或者!-x操作符 实例：1234567if ($http_cookie ~* &quot;id=([^;]+)(?:;|$)&quot;) &#123; set $id $1;&#125;if ($http_user_agent ~ MSIE) &#123; rewrite ^(.*)$ /msie/$1 break;&#125; 3.3.return 语法： return code； return url； return code url； 默认值：none 配置段：server,location,if 作用： 停止处理，并为客户端返回状态码。 非标准的444状态码将关闭连接，不发送任何响应头 可以使用的状态码有：204/400/402-406/408/410/411/413/416/500-504 如果状态码后面是一个url，该url将成为location头的补值。 没有状态码的url将被视为一个默认的302状态码 状态码附带文字段落，该文本将被放置在响应主体里 实例：123456if ($request_method = POST) &#123; return 405;&#125;if ($invalid_referer) &#123; return 403;&#125; 3.4.rewrite 语法：rewrite regex replacement [flag]; 默认值：none 配置段：server,location,if 作用： 如果一个URI匹配指定的正则表达式regex，URI就按照replacement重写 可以在重写指令后添加标识【flag】 flag标志可以停止继续处理 如果replacement以”http://“或”https://“开始，将不再继续处理rewrite指令，这个重定向将返回给客户端 flag标识符可为以下值： last：停止处理后续rewrite指令集，然后对当前重写的新URI在rewrite指令集上重新查找。 break：完成rewrite指令，并不在重新查找,但是当前location内剩余非rewrite语句和location外的的非rewrite语句可以执行。 redirect：如果replacement不是以http:// 或https://开始，返回302临时重定向 permannet：返回301永久重定向 最终完整的重定向URL包括请求scheme(http://,https://等),请求的server_name_in_redirect和 port_in_redirec三部分 ，说白了也就是http协议 域名 端口三部分组成。 实例：12345location /download/ &#123; rewrite ^(/download/.*)/media/(.*)..*$ $1/mp3/$2.mp3 break; rewrite ^(/download/.*)/audio/(.*)..*$ $1/mp3/$2.ra break; return 403;&#125; 3.5.rewrite_log 语法：rewrite_log on|off; 默认值：rewrite_log off; 配置段：http,server,location,if 作用：启用时将在error log中记录notice级别的重写日志 实例：12rewrite_log on;error_log logs/xxx.error.log notice; 3.6.set 语法：set variable value; 默认值：none 配置段：server,location,if 作用：定义一个变量并赋值，值可以是文本，变量或者文本变量混合体。3.7.uninitialized_variable_warn 语法：uninitialized_variable_warn on | off; 默认值：uninitialized_variable_warn on 作用域：http,server,location,if 作用：控制是否记录未初始化的警告信息 4.rewrite的规则4.1.rewrite指令执行顺序 执行server块的rewrite指令(这里的块指的是server关键字后{}包围的区域，其它xx块类似) 执行location匹配 执行选定的location中的rewrite指令 如果其中某步URI被重写，则重新循环执行1-3，直到找到真实存在的文件如果循环超过10次，则返回500 Internal Server Error错误4.2.正则表达式-引用取值 可以使用括号来捕获，后续可用位置来将其引用，位置变量取决于捕获正则表达式中的顺序，$1引用第一个括号（）中值，$2则引用第二个括号中的值 实例： 1^/img/([a-z]&#123;2&#125;)/([a-z0-9]&#123;5&#125;)/(.*)\\.(png|gif|jpg)$ 1） $1:是([a-z]{2})，两个小写字母组成的字符串2） $2:是([a-z0-9]{5})，由小写字母或0-9组成的5个字符串3） $3:是(.*)，是文件名4） $4:是(png|gif|jpg)，其中一个 4.3.return返回规则 停止处理，并为客户端返回状态码。 非标准的444状态码将关闭连接，不发送任何响应头 可以使用的状态码有：204/400/402-406/408/410/411/413/416/500-504 如果状态码后面是一个url，该url将成为location头的补值。 没有状态码的url将被视为一个默认的302状态码 状态码附带文字段落，该文本将被放置在响应主体里123location = /img404.html&#123; return 404 &quot;image not found\\n&quot;; &#125; 5.rewrite小实例5.1.禁止.sh .bash123location ~ .*\\.(sh|bash)?$&#123; return 403; &#125; 5.2.目录跳转123456789location /a&#123; alias /data/site/b.chen.com/a; rewrite ^/a/?$ /b last;&#125;location /b&#123; alias /data/site/b.chen.com/b; default_type &apos;text/html&apos;; echo &quot;url is a -&gt; rewrite to b...&quot;;&#125; 5.3.防盗链实例5.3.0.valid_referer指令说明Nginx配置中有一个指令valid_referers，用来获取Referer头域中的值，并且根据该值的情况给Nginx全局变量$invalid_referer的值，如果Referer头域中没有符合valid_referers指令配置的值，$invalid_referer变量将会被赋值为1。valid_referer指令的语法结构为：123456valid_referers none | blocked | server_names | string ....;none 检测Referer头域不存在的请求blocked 检测Referer头域的值被防火墙或者代理服务器删除或伪装的情况。这种情况下，该头域的值不以“http://”或者“https：//”开头server_names 设置一个或多个URL,检测Referer头域的值是否是这些URL中的某个。从nginx 0.5.33以后支持使用通配符“*”。 5.3.1.nginx.conf的server配置12345678910111213141516171819server&#123; server_name echo.chen.com; listen 80; location /&#123; root /data/site/echo.chen.com; index index.html; &#125; location ~ .*\\.(jpg|png)$ &#123; valid_referers none blocked echo.chen.com; if ($invalid_referer) &#123; return 412; break; &#125; root /data/site/echo.chen.com; &#125; location =/error.html&#123; root /data/site/echo.chen.com; &#125;&#125; /data/site/echo.chen.com 自行创建目录 index.html内容如下：12this is index.html&lt;img src=&quot;http://echo.chen.com/1.jpg&quot;&gt; 5.3.2.Windows下host配置12192.168.1.111 b.chen.com192.168.1.111 echo.chen.com 配置不同域名指定同一个ip，以便测试5.3.3.浏览器测试访问指定的域名，即可访问到图片使用b.chen.com进行访问则不能访问到服务器图片 5.4.域名跳转12345678910111213141516server&#123; server_name jump.chen.com; listen 80; access_log off; location /&#123; default_type &quot;text/html&quot;; echo &quot;it is echo.chen.com jump to jump.chen.com&quot;; &#125;&#125;server&#123; server_name echo.chen.com; listen 80; rewrite ^/ http://jump.chen.com/; location /&#123; &#125;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"Nginx location配置解析","slug":"nginx/Nginx location配置解析","date":"2017-08-24T15:34:12.000Z","updated":"2018-03-28T13:12:08.614Z","comments":true,"path":"2017/08/24/nginx/Nginx location配置解析/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/24/nginx/Nginx location配置解析/","excerpt":"","text":"Nginx location配置解析1.语法规则1location [=|~|~*|^~]/uri/&#123;...&#125; = 表示精确匹配，这个优先级最高的 ^~ 表示uri以某个常规字符串开头，理解为匹配 url路径即可，Nginx不对url做编码，因此请求为/static/80%/aa,可以被规则^~/static/ /aa(注意中间是空格) ~ 表示区分大小写的正则匹配、 ~* 表示不区分大小写的正则匹配 !~ 表示区分大小写不正则匹配 !~*表示不区分大小写不正则匹配 / 表示通用匹配，任何请求都会匹配到，默认匹配其中常用正则 . ： 匹配除换行符以外的任意字符 ? ： 重复0次或1次 + ： 重复1次或更多次 * ： 重复0次或更多次 \\d ：匹配数字 ^ ： 匹配字符串的开始 $ ： 匹配字符串的介绍 {n} ： 重复n次 {n,} ： 重复n次或更多次 [c] ： 匹配单个字符c [a-z] ： 匹配a-z小写字母的任意一个2.语法优先级别优先级：= &gt; ^~首先匹配 = ，其次匹配 ^~，其次是按文件中顺序的正则匹配，最后是交给 / 通用匹配。当有匹配成功时候，停止匹配，按当前匹配规则请求。3.定义匹配规则(注：需要安装echo模块才行，才能使用echo)123location / &#123; echo &apos;/&apos;;&#125; 123location = /&#123; echo &apos;=/&apos;;&#125; 123location = /nginx&#123; echo &apos;=/nginx&apos;;&#125; 123location ~ \\.(gif|jpg|png|js|css) &#123; echo &apos;name-gif/jpg/png&apos;;&#125; 123location ~* \\.png$ &#123; echo &apos;all-png&apos;;&#125; 123location ^~ /static/ &#123; echo &apos;static&apos;;&#125; 4.访问测试 访问http://a.chen.com/，匹配到“=/” 12#curl http://a.chen.com/=/ 访问http://a.chen.com/nginx，完全匹配到“=/nginx” 12#curl http://a.chen.com/nginx=/nginx 访问http://a.chen.com/xxx/xxx.PNG，完全匹配到“~* .png$，因为大写。所以没有匹配到‘~.(gif|jpg|png|js|css)’，因为 ~ 区分大小写 ” 12#curl http://a.chen.com/xxx/1.PNGall-png 访问http://a.chen.com/static/xxx.PNG，匹配到“ ^~ /static/ 因为有 ^~ 停止往下匹配了” 12#curl http://a.chen.com/static/1.PNGstatic 5.常用的静态资源匹配规则5.1.样式和JS1234location ~* .*\\.(js|css)?$&#123; expires 7d;//7天过期 access_log off;//不保存日志&#125; 5.5.图片图标等1234location ~* .*\\.(jpg|png|gif|jpeg|bmp|ico)?$&#123; expires 7d;//7天过期 access_log off;//不保存日志&#125; 5.6.资源数据123location ~* .*\\.(zip|rar|exe|msi|iso|gho|mp3|mp4|rmvb|wma|wmv|rm)?$&#123; deny all;//禁止这些文件的下载&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"Nginx 日志配置详情解析","slug":"nginx/Nginx 日志配置详情解析","date":"2017-08-24T13:22:56.000Z","updated":"2018-03-28T13:11:38.627Z","comments":true,"path":"2017/08/24/nginx/Nginx 日志配置详情解析/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/24/nginx/Nginx 日志配置详情解析/","excerpt":"","text":"Nginx 日志配置详情解析&emsp;&emsp;在使用nginx进行服务器管理时候，日志对于统计、审查、排错来说非常有利。&emsp;&emsp;nginx日志相关的配置有：access_log(访问日志)、log_format（日志格式）、open_log_file_cache、log_not_found、log_subrequest、rewrite_log、error_log。&emsp;&emsp;nginx有一个非常灵活的日志记录模式，每个级别的配置可以有各自独立的访问日志。日志格式通过log_format命令来定义。（主要基于ngx_http_log_module:用于定义请求日志格式） 1.access_log配置解析1.1.access_log语法 access_log path [format [buffer=size [flush=time]]] access_log path format gzip[=level] [buffer=size [flush=time]] access_log syslog:server=address[,parameter=value][format] access_log off1.2.access_log默认值 access_log log/access.log combined1.3.access_log配置段 http server location if in location limit_except1.4.access_log语法参数解析 gzip：压缩等级 buffer：设置所需内容缓存区大小 flush：保存在缓存区的最长时间 off：不记录日志 combined：使用默认的格式记录日志（access_log log/access.log combined或access_log log/access.log） 2.log_format配置解析2.1.log_format语法 log_format name string …;2.2.log_format默认值 log_format combined “…”;log_format有一个默认的无需设置的combined日志格式，相当于apache的combined日志格式。格式如下：123log_format combined &apos;$remote_addr - $remote_user [$time_local] &apos; &apos; &quot;$request&quot; $status $body_bytes_sent &apos; &apos; &quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos;; 2.3.log_format配置段 http2.4.log_format语法参数解析 name表示格式名称 string表示等义的格式。2.5.log_format常用的变量参数：12345678910111213141516$remote_addr, $http_x_forwarded_for（反向） 记录客户端IP地址$remote_user 记录客户端用户名称$request 记录请求的URL和HTTP协议$status 记录请求状态$body_bytes_sent 发送给客户端的字节数，不包括响应头的大小； 该变量与Apache模块mod_log_config里的“%B”参数兼容。$bytes_sent 发送给客户端的总字节数。$connection 连接的序列号。$connection_requests 当前通过一个连接获得的请求数量。$msec 日志写入时间。单位为秒，精度是毫秒。$pipe 如果请求是通过HTTP流水线(pipelined)发送，pipe值为“p”，否则为“.”。$http_referer 记录从哪个页面链接访问过来的$http_user_agent 记录客户端浏览器相关信息$request_length 请求的长度（包括请求行，请求头和请求正文）。$request_time 请求处理时间，单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。$time_iso8601 ISO8601标准格式下的本地时间。$time_local 通用日志格式下的本地时间。 2.6.log_format使用例子2.6.1.nginx反向代理时配置log_format123log_format porxy &apos;$http_x_forwarded_for - $remote_user [$time_local] &apos; &apos; &quot;$request&quot; $status $body_bytes_sent &apos; &apos; &quot;$http_referer&quot; &quot;$http_user_agent&quot; &apos;; 注：nginx位于负载均衡器，squid，nginx反向代理之后，web服务器无法直接获取到客户端真实的IP地址了。 $remote_addr获取反向代理的IP地址。反向代理服务器在转发请求的http头信息中，可以增加X-Forwarded-For信息，用来记录 客户端IP地址和客户端请求的服务器地址。 2.6.2.http发送给客户端时配置log_format123456789101112131415161718192021http &#123; log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;&quot;$status&quot; $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot; &apos; &apos;&quot;$gzip_ratio&quot; $request_time $bytes_sent $request_length&apos;; log_format srcache_log &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;&quot;$status&quot; $body_bytes_sent $request_time $bytes_sent $request_length &apos; &apos;[$upstream_response_time] [$srcache_fetch_status] [$srcache_store_status] [$srcache_expire]&apos;; open_log_file_cache max=1000 inactive=60s; server &#123; server_name ~^(www\\.)?(.+)$; access_log logs/$2-access.log main; error_log logs/$2-error.log; location /srcache &#123; access_log logs/access-srcache.log srcache_log; &#125; &#125;&#125; 注：发送给客户端的响应头拥有“sent_http_”前缀。 比如$sent_http_content_range。 3.open_log_file_cache配置解析3.1.open_log_file_cache语法 open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time]; open_log_file_cache off;3.2.open_log_file_cache默认值 open_log_file_cache off;3.3.open_log_file_cache配置段 http server location3.4.open_log_file_cache语法参数解析 max:设置缓存中的最大文件描述符数量，如果缓存被占满，采用LRU算法将描述符关闭。 inactive:设置存活时间，默认是10s min_uses:设置在inactive时间段内，日志文件最少使用多少次后，该日志文件描述符记入缓存中，默认是1次 valid:设置检查频率，默认60s off：禁用缓存3.5.open_log_file_cache的作用对于每一条日志记录，都将是先打开文件，再写入日志，然后关闭。可以使用open_log_file_cache来设置日志文件缓存(默认是off)3.6.open_log_file_cache使用例子12open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2;open_log_file_cache off; 4.log_not_found配置解析4.1.log_not_found语法 log_not_found on | off;4.2.log_not_found默认值 log_not_found on;4.3.log_not_found配置段 http server location4.4.log_not_found的作用是否在error_log中记录不存在的错误。默认是。 5.log_subrequest配置解析5.1.log_subrequest语法 log_subrequest on | off;5.2.log_subrequest默认值 log_subrequest off;5.3.log_subrequest配置段 http server location5.4.log_subrequest的作用是否在access_log中记录子请求的访问日志。默认不记录。 6.rewrite_log配置解析6.1.rewrite_log语法 rewrite_log on | off;6.2.rewrite_log默认值 rewrite_log off;6.3.rewrite_log配置段 http server location if6.4.rewrite_log的作用启用时将在error log中记录notice级别的重写日志。基于ngx_http_rewrite_module模块提供的。用来记录重写日志的。对于调试重写规则建议开启。 7.error_log配置解析7.1.error_log语法 error_log file | stderr | syslog:server=address[,parameter=value] [debug | info | notice | warn | error | crit | alert | emerg];7.2.error_log默认值 error_log logs/error.log error;7.3.error_log配置段 http server location main7.4.error_log的作用配置错误日志。","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"服务器快速集成Nginx","slug":"nginx/服务器集成Nginx","date":"2017-08-22T07:23:54.000Z","updated":"2018-03-28T13:11:04.346Z","comments":true,"path":"2017/08/22/nginx/服务器集成Nginx/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/22/nginx/服务器集成Nginx/","excerpt":"","text":"服务器快速集成Nginx1.安装依赖1.1.pcre重定向依赖1yum -y install pcre* PCRE(Perl Compatible Regular Expressions)是一个Perl库，不止具有http重定向依赖，还包括 perl 兼容的正则表达式库。nginx的http模块使用pcre来解析正则表达式，所以需要在linux上安装pcre库。 1.2.openssl(http/https支持，如果不需要https可以不安装。1yum -y install pcre* OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。 1.3.安装 Tengine 执行配置命令 gcc环境1yum -y install gcc gcc-c++ autoconf automake make 若是本机上已经安装则可以忽略，主要用于编译Nginx源码 2.下载解压2.1.下载1wget http://nginx.org/download/nginx-1.12.2.tar.gz 2.2.解压先创建Nginx存放路径，再进行解压1cd /usr/local/ 1mkdir nginxgz 1tar -zxvf nginx-1.7.8.tar.gz -C /usr/local/nginxgz 3.编译安装Nginx1cd /usr/local/nginxgz/nginx-1.12.2 1./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module --with-http_stub_status_module --with-pcre –with-http_ssl_module ： 支持https –with-http_stub_status_module ： 支持nginx状态查询 –with-http_v2_module ： 支持Google发明的SPDY协议，必须有ssl的支持 –with-pcre ： 支持rewrite重写功能，必须有pcre注：若是没有安装gcc则会报如下错误：123checking for OS + Linux 2.6.32-431.el6.x86_64 x86_64checking for C compiler ... not found 编译：1make 1make install 4.操作Nginx 启动： 1/usr/local/nginx/sbin/nginx 重启： 1/usr/local/nginx/sbin/nginx -s reload 关闭： 1/usr/local/nginx/sbin/nginx -s stop 5.配置防火墙（iptables）测试5.1.关闭防火墙1service iptables stop 5.2.编辑配置文件1vi /etc/sysconfig/iptables 5.3.开发80端口1-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT 5.4.重启服务1service iptables restart 测试，浏览器输入服务器地址（如：192.168.1.111） 6.将Nginx添加到服务（service）中 6.1.切换到启动脚本 1cd /etc/init.d 6.2.创建nginx文件 1touch nginx 6.3.编辑nginx文件 1vim /etc/init.d/nginx 6.4.并且添加以下内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596#!/bin/bash # nginx Startup script for the Nginx HTTP Server # # chkconfig: - 85 15 # description: Nginx is a high-performance web and proxy server. # It has a lot of features, but it&apos;s not for everyone. # processname: nginx # pidfile: /var/run/nginx.pid # config: /usr/local/nginx/conf/nginx.conf nginxd=/usr/local/nginx/sbin/nginx nginx_config=/usr/local/nginx/conf/nginx.conf nginx_pid=/usr/local/nginx/nginx.pid RETVAL=0 prog=&quot;nginx&quot; # Source function library. . /etc/rc.d/init.d/functions # Source networking configuration. . /etc/sysconfig/network # Check that networking is up. [ $&#123;NETWORKING&#125; = &quot;no&quot; ] &amp;&amp; exit 0 [ -x $nginxd ] || exit 0 # Start nginx daemons functions. start() &#123; if [ -e $nginx_pid ];then echo &quot;nginx already running....&quot; exit 1 fi echo -n $&quot;Starting $prog: &quot; daemon $nginxd -c $&#123;nginx_config&#125; RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; touch /var/lock/subsys/nginx return $RETVAL &#125; # Stop nginx daemons functions. stop() &#123; echo -n $&quot;Stopping $prog: &quot; killproc $nginxd RETVAL=$? echo [ $RETVAL = 0 ] &amp;&amp; rm -f /var/lock/subsys/nginx /var/run/nginx.pid &#125; # reload nginx service functions. reload() &#123; echo -n $&quot;Reloading $prog: &quot; $nginxd -s reload #if your nginx version is below 0.8, please use this command: &quot;kill -HUP `cat $&#123;nginx_pid&#125;`&quot; RETVAL=$? echo &#125; # See how we were called. case &quot;$1&quot; in start) start ;; stop) stop ;; reload) reload ;; restart) stop start ;; status) status $prog RETVAL=$? ;; *) echo $&quot;Usage: $prog &#123;start|stop|restart|reload|status|help&#125;&quot; exit 1 esac exit $RETVAL 注：12# chkconfig: - 85 15# description: nginx is a World Wide Web server. It is used to serve 脚本中这两个不能去除，不然不能启动，而且会报以下错误，即语法错误 1nginx 服务不支持 chkconfig chkconfig语法： 1语 法：chkconfig [--add][--del][--list][系统服务] 或 chkconfig [--level &lt;等级代号&gt;][系统服务][on/off/reset] 6.5.保存退出后，切换路径 1cd /etc/rc.d/init.d 6.6.设置权限 1chmod +x nginx 6.7.chkconfig改变nginx运行级别 1/sbin/chkconfig --level 345 nginx on 到此为止：任何位置都能运行 service nginx start 可选 start | stop | restart | reload | status | help","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"Nginx 动态添加模块","slug":"nginx/Nginx 动态添加模块","date":"2017-08-22T05:23:42.000Z","updated":"2018-03-28T13:10:36.125Z","comments":true,"path":"2017/08/22/nginx/Nginx 动态添加模块/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/22/nginx/Nginx 动态添加模块/","excerpt":"","text":"Nginx 动态添加模块nginx模块依赖：nginx的一些模块需要第三方支持，例如gzip模块需要zlib库，rewrite模块需要pcre库，ssl功能需要openssl库。根据需求添加不同模块例添加echo模块： 1.下载并安装nginx详情请看：http://blog.csdn.net/dushiwodecuo/article/details/78393454 2.查看nginx已安装的模块1/usr/local/nginx/sbin/nginx -V 旧版本模块1./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module --with-http_stub_status_module --with-pcre 3.选择与nginx版本所符合的模块版本echo：https://github.com/openresty/echo-nginx-module/tags当前nginx版本为：1.12.2，选择echo版本为0.61 4.下载模块1wget https://github.com/openresty/echo-nginx-module/archive/v0.61.tar.gz 5.解压模块1tar -zxvf v0.61.tar.gz -C /usr/local/nginxgz 6.为nginx添加模块6.1.切换到nginx的源码目录(即解压后的目录)1cd /usr/local/nginxgz/nginx-1.12.2 6.2.添加新模块1./configure --prefix=/usr/local/nginx --add-module=/usr/local/nginxgz/echo-nginx-module-0.61 --with-http_ssl_module --with-http_v2_module --with-http_stub_status_module --with-pcre 7.重新编译12makemake install 8.测试 Linux上的测试8.1.修改配置文件8.1.1.修改nginx.conf，添加测试域名模块1234567server&#123; server_name echo.chen.com; listen 80; location /&#123; echo &quot;it is echo module...&quot;; &#125; &#125; 8.1.2.修改Linux host文件1echo &apos;192.168.1.111 echo.chen.com&apos; &gt;&gt; /etc/hosts 8.2.重启nginx1/usr/local/nginx/sbin/nginx -s reload 注：若是重启nginx之后还没能访问到，直接reboot，重启虚拟机等即可8.3.访问测试 Windows上浏览器测试 8.1.修改配置文件8.1.1.修改nginx.conf，添加测试域名模块12345678server&#123; server_name echo.chen.com; listen 80; location /&#123; default_type &apos;text/html&apos;; echo &quot;it is echo module...&quot;; &#125; &#125; 注： 如果没有这个default_type,浏览器访问则会一直下载文件而不是输出在浏览器上 8.1.2.修改Windows host文件1192.168.1.111 echo.chen.com 8.2.重启nginx1/usr/local/nginx/sbin/nginx -s reload 注：若是重启nginx之后还没能访问到，直接reboot，重启虚拟机等即可8.3.测试访问浏览器","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"Nginx 的ngx_http_core_module模块","slug":"nginx/nginx 的ngx_http_core_module模块处理请求","date":"2017-08-20T02:40:56.000Z","updated":"2018-03-28T13:06:19.781Z","comments":true,"path":"2017/08/20/nginx/nginx 的ngx_http_core_module模块处理请求/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/20/nginx/nginx 的ngx_http_core_module模块处理请求/","excerpt":"","text":"Nginx 的ngx_http_core_module模块ngx_http_core_module模块处理请求时，会有大量的变量，这些变量可以通过访问日志来记录，也可以用于其他nginx模块接收。在对请求做策略入改写等到都会使用到一些变量。以下为ngx_http_core_module模块提供的变量总结：123456789101112131415161718192021222324252627282930313233343536$arg_PARAMETER ``` - HTTP 请求中某个参数的值，如/get?value=a.chen.com，可以用$arg_site取得a.chen.com这个值.``` $args ``` - HTTP 多个请求参数，请求中的完整参数。例如，在请求/get?a=1&amp;b=2 中，$args表示字符串a=1&amp;b=2. ``` $binary_remote_addr``` - 二进制格式的客户端地址。例如：\\x0B\\xE0C\\x0A``` $body_bytes_sent``` - 表示在向客户端发送的http响应中，包体部分的字节数 ``` $content_length``` - 表示客户端请求头部中的Content-Length 字段的内容``` $content_type``` - 表示客户端请求头部中的Content-Type 字段的类型``` $cookie_COOKIE``` - 表示在客户端请求头部中的cookie 字段的内容 ``` $document_root ``` - 表示当前请求所使用的root 配置项的值 ``` $uri``` - 表示当前请求的URI，不带任何参数 $document_uri1- 与$uri 含义相同 $request_uri123- 表示客户端发来的原始请求URI，带完整的参数。$uri和$document_uri未必是用户的原始请求，在内部重定向后可能是重定向后的URI，而$request_uri 永远不会改变，始终是客户端的原始URI. ``` $http_HEADER 表示当前 HTTP请求中相应头部的值。HEADER名称全小写。例如，示请求中 Host头部对应的值 用 $http_host表 1$host 表示客户端请求头部中的Host字段。如果Host字段不存在，则以实际处理的server（虚拟主机）名称代替。如果Host字段中带有端口，如IP:PORT，那么$host是去掉端口的，它的值为IP。$host 是全小写的。这些特性与http_HEADER中的http_host不同，http_host只取出Host头部对应的值。 1$hostname 表示 Nginx所在机器的名称，与 gethostbyname调用返回的值相同 1$sent_http_HEADER 表示返回客户端的 HTTP响应中相应头部的值。HEADER名称全小写。例如，用 $sent_http_content_type表示响应中 Content-Type头部对应的值 1$is_args 表示请求中的 URI 是否带参数，如果带参数，$is_args值为 ?，如果不带参数，则是空字符串,可以用于条件判断 1$limit_rate 表示当前连接的限速是多少，0表示无限速 1$nginx_version 表示当前 Nginx的版本号 1$query_string 请求 URI中的参数，与 $args相同，然而 $query_string是只读的不会改变 1$remote_addr 表示客户端的地址 1$remote_port 表示客户端连接使用的端口 1$remote_user 表示使用 Auth Basic Module时定义的用户名 1$request_filename 表示用户请求中的 URI 经过 root或 alias转换后的文件路径 1$request_body 表示 HTTP请求中的包体，该参数只在 proxy_pass 或 fastcgi_pass 中有意义 1$request_body_file 表示 HTTP请求中的包体存储的临时文件名 1$request_completion 当请求已经全部完成时，其值为 “ok”。若没有完成，就要返回客户端，则其值为空字符串；或者在断点续传等情况下使用 HTTP range 访问的并不是文件的最后一块，那么其值也是空字符串。 1$request_method 表示 HTTP 请求的方法名，如 GET、PUT、POST等 1$scheme 表示 HTTP scheme，如在请求 https://nginx.com/中表示 https 1$server_addr 表示服务器地址 1$server_name 表示服务器名称 1$server_port 表示服务器端口 $server_protocol 表示服务器向客户端发送响应的协议，如 HTTP/1.1或 HTTP/1.0","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/categories/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.catalpaflat.cn/tags/Nginx/"}]},{"title":"JavaEE 微信境外支付","slug":"支付/微信支付/JavaEE 微信境外支付","date":"2017-08-05T02:33:12.000Z","updated":"2018-04-01T07:46:18.609Z","comments":true,"path":"2017/08/05/支付/微信支付/JavaEE 微信境外支付/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/05/支付/微信支付/JavaEE 微信境外支付/","excerpt":"","text":"JavaEE 微信境外支付 API文档 境外分为两种： 普通商户版 服务商版 普通商户版： 1.支付方式: 刷卡支付 公众号支付 扫码支付 APP支付 2.报关接口：用于商户提交海关需要的订单附近信息 服务商版包括的支付方式有： 刷卡支付 公众号支付 扫码支付 1. 普通商户版1.1 刷卡支付 详情API文档. 应用场景:收银员使用扫码设备读取微信用户刷卡授权码以后，二维码或条码信息传送至商户收银台，由商户收银台或者商户后台调用该接口发起支付。 ⚠️提醒1：提交支付请求后微信会同步返回支付结果。当返回结果为“系统错误”时，商户系统等待5秒后调用【查询订单API】，查询支付实际交易结果；当返回结果为“USERPAYING”时，商户系统可设置间隔时间(建议10秒)重新查询支付结果，直到支付成功或超时(建议30秒)； ⚠️提醒2：在调用查询接口返回后，如果交易状况不明晰，请调用【撤销订单API】，此时如果交易失败则关闭订单，该单不能再支付成功；如果交易成功，则将扣款退回到用户账户。当撤销无返回或错误时，请再次调用。注意：请勿扣款后立即调用【撤销订单API】,建议至少15秒后再调用。撤销订单API需要双向证书。 1.1.1 接口url： https://apihk.mch.weixin.qq.com/pay/micropay （建议接入点：东南亚） https://apius.mch.weixin.qq.com/pay/micropay （建议接入点：其它） https://api.mch.weixin.qq.com/pay/micropay （建议接入点：中国国内） 1.1.2 与境内对比参数除了以下参数，其他都和国内一致。 名称 变量名 必填 类型 示例值 描述 版本号 version 否 String(32) 1.0 固定值 1.0 商品详情 detail 否 String(6000) 商品详细列表，使用Json格式，传输签名前请务必使用CDATA标签将JSON文本串保护起来。 商品详情类型 123456789101112&#123;\"goods_detail\":[&#123; \"goods_name\":\"iPhone6s 16G\",\"quantity\":1, &#125;,&#123; \"goods_name\":\"iPhone6s 32G\",\"quantity\":1, &#125;]&#125; 商品详情描述 123goods_detail└ goods_name String 必填 256 商品名称└ quantity Int 必填4 商品数量 1.1.3 支付方式： 免密支付流程 验密支付流程 1.2 公众号支付 注意：商户也可以把商品网页的链接生成二维码，用户扫一扫打开后即可完成购买支付。 交互细节： 以下是支付场景的交互细节，请认真阅读，设计商户页面的逻辑： （1）用户打开商户网页选购商品，发起支付，在网页通过JavaScript调用getBrandWCPayRequest接口，发起微信支付请求，用户进入支付流程。 （2）用户成功支付点击完成按钮后，商户的前端会收到JavaScript的返回值。商户可直接跳转到支付成功的静态页面进行展示。 （3）商户后台收到来自微信开放平台的支付成功回调通知，标志该笔订单支付成功。 注：（2）和（3）的触发不保证遵循严格的时序。JS API返回值作为触发商户网页跳转的标志，但商户后台应该只在收到微信后台的支付成功回调通知后，才做真正的支付成功的处理。 1.2.1 接口url： https://apihk.mch.weixin.qq.com/pay/unifiedorder （建议接入点：东南亚） https://apius.mch.weixin.qq.com/pay/unifiedorder （建议接入点：其它） https://api.mch.weixin.qq.com/pay/unifiedorder （建议接入点：中国国内） 注：商户可根据实际请求情况选择最优域名进行访问，建议在接入时做好兼容，当访问其中一个域名出现异常时，可自动切换为其他域名。 1.2.2 与境内对比参数和刷卡支付一样的参数区别。 1.3 扫码支付几乎和公众号支付相同 1.4 APP支付 商户系统先调用该接口在微信支付服务后台生成预支付交易单，返回正确的预支付交易回话标识后再在APP里面调起支付。 除了请求参数“版本号” 和“商品详情” 不一样，其他都和境内一致。 1.5 报关接口 用于商户提交海关需要的订单附件信息。报关接口只支持一个月内的支付订单进行报关申请。以下为财付通的海关备案信息，一般海关会提供，如果没有请参考下表：财付通海关备案名称：财付通支付科技有限公司财付通10位海关注册编码：440316T004 1.5.1 订单附加信息提交接口 详情API 1.5.1.1 urlURL地址：https://api.mch.weixin.qq.com/cgi-bin/mch/customs/customdeclareorder 重点注意：请求接口前请先在以下页面提交您的海关信息，所有你需要报关的海关信息都需要提交，且信息真实有效：https://pay.weixin.qq.com/index.php/extend/customs 1.5.2 订单附加信息查询接口 商户通过订单号查询提交的订单附加信息。如果是微信收集的实名信息，查询接口不返回实名信息内容. 详情API 2. 服务商版 详情API文档 2.1 刷卡支付2.1.1 urlhttps://api.mch.weixin.qq.com/pay/micropay 2.1.1 参数区别和普通商户版刷卡支付一样的参数区别。 2.2 公众号支付 详情API文档 2.2.1 urlhttps://api.mch.weixin.qq.com/pay/unifiedorder 2.2.2 参数区别： 名称 变量名 必填 类型 示例值 描述 商品ID product_id 否 String(32) 12235413214070356458058 trade_type=NATIVE，此参数必传。此id为二维码中包含的商品ID，商户自行定义。 用户标识 openid 否 String(128) oUpF8uMuAJO_M2pxb1Q9zNjWeS6o trade_type=JSAPI，此参数必传，用户在主商户appid下的唯一标识。openid和sub_openid可以选传其中之一，如果选择传sub_openid,则必须传sub_appid。下单前需要调用【网页授权获取用户信息】接口获取到用户的Openid。 用户子标识 sub_openid 否 String(128) oUpF8uMuAJO_M2pxb1Q9zNjWeS6o trade_type=JSAPI，此参数必传，用户在子商户appid下的唯一标识。openid和sub_openid可以选传其中之一，如果选择传sub_openid,则必须传sub_appid。下单前需要调用【网页授权获取用户信息】接口获取到用户的Openid。 2.3 扫码支付 详情API文档 和公众号支付一致。","categories":[{"name":"支付","slug":"支付","permalink":"https://blog.catalpaflat.cn/categories/支付/"}],"tags":[{"name":"微信支付","slug":"微信支付","permalink":"https://blog.catalpaflat.cn/tags/微信支付/"}]},{"title":"JavaEE 支付宝支付","slug":"支付/支付宝支付/JavaEE 支付宝支付","date":"2017-08-04T11:33:12.000Z","updated":"2018-03-30T12:10:54.186Z","comments":true,"path":"2017/08/04/支付/支付宝支付/JavaEE 支付宝支付/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/04/支付/支付宝支付/JavaEE 支付宝支付/","excerpt":"","text":"JavaEE 支付宝支付 开发文档大全 支付宝已经更新添封装好的签名方法,可以在自己的项目中直接调用进行签名,减少了自己手动签名产生的问题,主要是在进行方法调用时注意传参的要求,尤其是公钥使用的是支付宝的公钥,而不是APP的公钥。 支付宝支付使用SDK进行对接API，会比微信好很多，已经封装好了，不同请求对象对应不同响应对象。 1. 支付宝—双对称加密支付宝与微信的不同之处： 微信是通过xml以及签名进行数据保护 支付宝是通过双对称加密进行数据保护 支付宝双对称加密： 用户先使用 RSA密钥工具 生成自身一对用户的对称秘钥（公钥和秘钥） 将公钥上传到支付宝（在创建应用时便会让用户提供） 支付宝会根据上传到公钥生成一对 支付宝的对称秘钥（公钥和秘钥） 支付宝双对称加密使用方式： 用户加签 的时候是用 用户的私钥 用户解密 的时候是用 支付宝的公钥 支付宝加签 的时候是用 支付宝的私钥 支付宝解密 的时候是用 用户的公钥 详情图解: 2. 支付宝常用API接口支付API： app支付接口2.0 手机网站支付接口2.0 统一收单交易退款查询 统一收单交易结算接口 统一收单交易关闭接口 统一收单交易撤销接口 统一收单交易退款接口 统一收单线下交易预创建 统一收单交易创建接口 统一收单交易支付接口 统一收单线下交易查询 3. Java Instance普通调用示例 1234567891011121314151617//实例化客户端AlipayClient alipayClient = new DefaultAlipayClient(\"https://openapi.alipay.com/gateway.do\", APP_ID, APP_PRIVATE_KEY, \"json\", CHARSET, ALIPAY_PUBLIC_KEY, \"RSA2\");//实例化具体API对应的request类,类名称和接口名称对应,当前调用接口名称：alipay.open.public.template.message.industry.modify AlipayOpenPublicTemplateMessageIndustryModifyRequest request = new AlipayOpenPublicTemplateMessageIndustryModifyRequest();//SDK已经封装掉了公共参数，这里只需要传入业务参数//此次只是参数展示，未进行字符串转义，实际情况下请转义request.setBizContent(\" &#123;\" +\" \\\"primary_industry_name\\\":\\\"IT科技/IT软件与服务\\\",\" +\" \\\"primary_industry_code\\\":\\\"10001/20102\\\",\" +\" \\\"secondary_industry_code\\\":\\\"10001/20102\\\",\" +\" \\\"secondary_industry_name\\\":\\\"IT科技/IT软件与服务\\\"\" +\" &#125;\");AlipayOpenPublicTemplateMessageIndustryModifyResponse response = alipayClient.execute(request); //调用成功，则处理业务逻辑if(response.isSuccess())&#123; //.....&#125; app支付接口2.0 AlipayClient alipayClient = new DefaultAlipayClient(\"https://openapi.alipay.com/gateway.do\",\"app_id\",\"your private_key\",\"json\",\"GBK\",\"alipay_public_key\",\"RSA2\"); AlipayTradeAppPayRequest request = new AlipayTradeAppPayRequest(); request.setBizContent(\"{\" + \"\\\"timeout_express\\\":\\\"90m\\\",\" + \"\\\"total_amount\\\":\\\"9.00\\\",\" + \"\\\"seller_id\\\":\\\"2088102147948060\\\",\" + \"\\\"product_code\\\":\\\"QUICK_MSECURITY_PAY\\\",\" + \"\\\"body\\\":\\\"Iphone6 16G\\\",\" + \"\\\"subject\\\":\\\"大乐透\\\",\" + \"\\\"out_trade_no\\\":\\\"70501111111S001111119\\\",\" + \"\\\"time_expire\\\":\\\"2016-12-31 10:05\\\",\" + \"\\\"goods_type\\\":\\\"0\\\",\" + \"\\\"promo_params\\\":\\\"{\\\\\\\"storeIdType\\\\\\\":\\\\\\\"1\\\\\\\"}\\\",\" + \"\\\"passback_params\\\":\\\"merchantBizType%3d3C%26merchantBizNo%3d2016010101111\\\",\" + \"\\\"royalty_info\\\":{\" + \"\\\"royalty_type\\\":\\\"ROYALTY\\\",\" + \" \\\"royalty_detail_infos\\\":[{\" + \" \\\"serial_no\\\":1,\" + \"\\\"trans_in_type\\\":\\\"userId\\\",\" + \"\\\"batch_no\\\":\\\"123\\\",\" + \"\\\"out_relation_id\\\":\\\"20131124001\\\",\" + \"\\\"trans_out_type\\\":\\\"userId\\\",\" + \"\\\"trans_out\\\":\\\"2088101126765726\\\",\" + \"\\\"trans_in\\\":\\\"2088101126708402\\\",\" + \"\\\"amount\\\":0.1,\" + \"\\\"desc\\\":\\\"分账测试1\\\",\" + \"\\\"amount_percentage\\\":\\\"100\\\"\" + \" }]\" + \" },\" + \"\\\"extend_params\\\":{\" + \"\\\"sys_service_provider_id\\\":\\\"2088511833207846\\\",\" + \"\\\"hb_fq_num\\\":\\\"3\\\",\" + \"\\\"hb_fq_seller_percent\\\":\\\"100\\\",\" + \"\\\"industry_reflux_info\\\":\\\"{\\\\\\\\\\\\\\\"scene_code\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\"metro_tradeorder\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"channel\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\"xxxx\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\"scene_data\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\"asset_name\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\"ALIPAY\\\\\\\\\\\\\\\"}}\\\",\" + \"\\\"card_type\\\":\\\"S0JP0000\\\"\" + \" },\" + \"\\\"sub_merchant\\\":{\" + \"\\\"merchant_id\\\":\\\"19023454\\\",\" + \"\\\"merchant_type\\\":\\\"alipay: 支付宝分配的间连商户编号, merchant: 商户端的间连商户编号\\\"\" + \" },\" + \"\\\"enable_pay_channels\\\":\\\"pcredit,moneyFund,debitCardExpress\\\",\" + \"\\\"store_id\\\":\\\"NJ_001\\\",\" + \"\\\"specified_channel\\\":\\\"pcredit\\\",\" + \"\\\"disable_pay_channels\\\":\\\"pcredit,moneyFund,debitCardExpress\\\",\" + \"\\\"settle_info\\\":{\" + \" \\\"settle_detail_infos\\\":[{\" + \" \\\"trans_in_type\\\":\\\"cardSerialNo\\\",\" + \"\\\"trans_in\\\":\\\"A0001\\\",\" + \"\\\"summary_dimension\\\":\\\"A0001\\\",\" + \"\\\"amount\\\":0.1\" + \" }]\" + \" },\" + \"\\\"invoice_info\\\":{\" + \"\\\"key_info\\\":{\" + \"\\\"is_support_invoice\\\":true,\" + \"\\\"invoice_merchant_name\\\":\\\"ABC|003\\\",\" + \"\\\"tax_num\\\":\\\"1464888883494\\\"\" + \" },\" + \"\\\"details\\\":\\\"[{\\\\\\\"code\\\\\\\":\\\\\\\"100294400\\\\\\\",\\\\\\\"name\\\\\\\":\\\\\\\"服饰\\\\\\\",\\\\\\\"num\\\\\\\":\\\\\\\"2\\\\\\\",\\\\\\\"sumPrice\\\\\\\":\\\\\\\"200.00\\\\\\\",\\\\\\\"taxRate\\\\\\\":\\\\\\\"6%\\\\\\\"}]\\\"\" + \" },\" + \"\\\"ext_user_info\\\":{\" + \"\\\"name\\\":\\\"李明\\\",\" + \"\\\"mobile\\\":\\\"16587658765\\\",\" + \"\\\"cert_type\\\":\\\"IDENTITY_CARD\\\",\" + \"\\\"cert_no\\\":\\\"362334768769238881\\\",\" + \"\\\"min_age\\\":\\\"18\\\",\" + \"\\\"fix_buyer\\\":\\\"F\\\",\" + \"\\\"need_check_info\\\":\\\"F\\\"\" + \" },\" + \"\\\"business_params\\\":\\\"{\\\\\\\"data\\\\\\\":\\\\\\\"123\\\\\\\"}\\\"\" + \" }\"); AlipayTradeAppPayResponse response = alipayClient.pageExecute(request); if(response.isSuccess()){ System.out.println(\"调用成功\"); } else { System.out.println(\"调用失败\"); }","categories":[{"name":"支付","slug":"支付","permalink":"https://blog.catalpaflat.cn/categories/支付/"}],"tags":[{"name":"支付宝支付","slug":"支付宝支付","permalink":"https://blog.catalpaflat.cn/tags/支付宝支付/"}]},{"title":"JavaEE 微信支付","slug":"支付/微信支付/JavaEE 微信支付","date":"2017-08-04T11:33:12.000Z","updated":"2018-04-01T07:46:32.593Z","comments":true,"path":"2017/08/04/支付/微信支付/JavaEE 微信支付/","link":"","permalink":"https://blog.catalpaflat.cn/2017/08/04/支付/微信支付/JavaEE 微信支付/","excerpt":"","text":"JavaEE 微信支付 微信境内支付包括： App支付 公众号支付 小程序支付 H5 支付 扫码支付 刷卡支付 除刷卡支付场景以外，商户系统先调用该接口在微信支付服务后台生成预支付交易单，返回正确的预支付交易回话标识后再按扫码、JSAPI、APP等不同场景生成交易串调起支付。 API 文档 1. 常用API 列表 统一下单（提交刷卡支付） 查询订单 关闭订单 申请退款 查询退款 下载对账账单 下载资金账单 支付结果通知 退款结果通知 2. 微信支付接口请求大致流程 封装请求参数 将请求参数进行sort() 对排序好的参数进行trim() 将参数拼接为正确顺序的uri并加入key（秘钥）到最后 将uri进行签名得到sign 将参数以及sign（排除秘钥）按顺序转为xml 请求对应接口（统一下单等） 响应时也是xml格式 转换xml为Map格式 校验returnCode和resultCode 3. 常用API中的区别点3.1 刷卡支付1.下单非统一下单，而是提交刷卡支付，即请求的url和其他几种都不同。 刷卡请求url：https://api.mch.weixin.qq.com/pay/micropay 其他统一下单url：https://api.mch.weixin.qq.com/pay/unifiedorde 2.提交刷卡支付参数中不能携带参数有以下：（其他类型支付均可）。 名称 变量名 必填 类型 示例值 描述 交易类型 trade_type 是 String(16) JSAPI JSAPI 公众号支付 NATIVE 扫码支付 APP APP支付 用户标识 openid 否 String(128) oUpF8uMuAJO_M2pxb1Q9zNjWeS6o trade_type=JSAPI时（即公众号支付），此参数必传，此参数为微信用户在商户对应appid下的唯一标识。openid如何获取，可参考【获取openid】。企业号请使用【企业号OAuth2.0接口】获取企业号内成员userid，再调用【企业号userid转openid接口】进行转换 通知地址 notify_url 是 String(256) http://www.weixin.qq.com/wxpay/pay.php 异步接收微信支付结果通知的回调地址，通知url必须为外网可访问的url，不能携带参数。 3.2 授权码提交刷卡支接口需要：auth_code. 名称 变量名 必填 类型 示例值 描述 授权码 auth_code 是 String(128) 120061098828009406 扫码支付授权码，设备读取用户微信中的条码或者二维码信息（注：用户刷卡条形码规则：18位纯数字，以10、11、12、13、14、15开头） 3.3 H5支付注⚠️：提醒：H5支付不建议在APP端使用，如需要在APP中使用微信支付，请接APP支付 名称 变量名 必填 类型 示例值 描述 场景信息 scene_info 是 String(256) 示例值 12345678//IOS移动应用&#123;&quot;h5_info&quot;: &#123;&quot;type&quot;:&quot;IOS&quot;,&quot;app_name&quot;: &quot;王者荣耀&quot;,&quot;bundle_id&quot;: &quot;com.tencent.wzryIOS&quot;&#125;&#125;//安卓移动应用&#123;&quot;h5_info&quot;: &#123;&quot;type&quot;:&quot;Android&quot;,&quot;app_name&quot;: &quot;王者荣耀&quot;,&quot;package_name&quot;: &quot;com.tencent.tmgp.sgame&quot;&#125;&#125;//WAP网站应用&#123;&quot;h5_info&quot;: &#123;&quot;type&quot;:&quot;Wap&quot;,&quot;wap_url&quot;: &quot;https://pay.qq.com&quot;,&quot;wap_name&quot;: &quot;腾讯充值&quot;&#125;&#125; 该字段用于上报支付的场景信息,针对H5支付有以下三种场景,请根据对应场景上报,H5支付不建议在APP端使用，针对场景1，2请接入APP支付，不然可能会出现兼容性问题 描述. 1，IOS移动应用 123456&#123;\"h5_info\": //h5支付固定传\"h5_info\" &#123;\"type\": \"\", //场景类型 \"app_name\": \"\", //应用名 \"bundle_id\": \"\" //bundle_id &#125;&#125; 2，安卓移动应用 123456&#123;\"h5_info\": //h5支付固定传\"h5_info\" &#123;\"type\": \"\", //场景类型 \"app_name\": \"\", //应用名 \"package_name\": \"\" //包名 &#125;&#125; 3，WAP网站应用 123456&#123;\"h5_info\": //h5支付固定传\"h5_info\" &#123;\"type\": \"\", //场景类型 \"wap_url\": \"\",//WAP网站URL地址 \"wap_name\": \"\" //WAP 网站名 &#125;&#125; 4. 微信境外支付JavaEE 微信境外支付","categories":[{"name":"支付","slug":"支付","permalink":"https://blog.catalpaflat.cn/categories/支付/"}],"tags":[{"name":"微信支付","slug":"微信支付","permalink":"https://blog.catalpaflat.cn/tags/微信支付/"}]},{"title":"分布式之消息中间件","slug":"消息队列/消息中间件","date":"2017-07-23T07:46:12.000Z","updated":"2018-03-28T13:03:30.944Z","comments":true,"path":"2017/07/23/消息队列/消息中间件/","link":"","permalink":"https://blog.catalpaflat.cn/2017/07/23/消息队列/消息中间件/","excerpt":"","text":"分布式之消息中间件 目录 1.消息中间件概述 2.消息中间件使用场景 3.消息中间件原理 4.消息中间件传递模式 4.1点对点模式（PTP） 4.2发布-订阅模型（Pub/Sub） 1.消息中间件概述&emsp;&emsp;消息中间件利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型，它可以在分布式环境下扩展进程间的通信。消息中间件就是用在消息队列服务器中用于过滤、区分和根据规则进行转发的程序。&emsp;&emsp;目前在生产环境，使用较多的消息中间件有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等&emsp;&emsp; 2.消息中间件使用场景&emsp;&emsp;消息中间件适用于需要可靠的数据传送的分布式环境。&emsp;&emsp;采用消息中间件机制的系统中，不同的对象之间通过传递消息来激活对方的事件，完成相应的操作。&emsp;&emsp;&emsp;&emsp;消息中间件能在不同平台之间通信，它常被用来屏蔽掉各种平台及协议之间的特性，实现应用程序之间的协同，其优点在于能够在客户和服务器之间提供同步和异步的连接，并且在任何时刻都可以将消息进行传送或者存储转发，这也是它比远程过程调用更进一步的原因。 3.消息中间件原理&emsp;&emsp;要了解消息中间件的原理，先了解MOM（面向消息的中间件）。&emsp;&emsp;面向消息的中间件（MOM），提供了以松散耦合的灵活方式集成应用程序的一种机制。它们提供了基于存储和转发的应用程序之间的异步数据发送，即应用程序彼此不直接通信，而是与作为中介的MOM通信。MOM提供了有保证的消息发送（至少是在尽可能地做到这一点），应用程序开发人员无需了解远程过程调用（PRC）和网络/通信协议的细节。&emsp;&emsp;消息中间件利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型，它可以在分布式环境下扩展进程间的通信。&emsp;&emsp; 4.消息中间件传递模式4.1点对点模式（PTP）&emsp;&emsp;PTP模式包含消息队列（Queue），发送者(Sender)。接收者(Receiver),每个消息都被发送到一个特定的队列，接收者从队列中获取消息。队列保留着消息，而且队列可以是持久的，以保证在消息服务出现故障时仍然能够传递消息，直到他们被消费或超时。&emsp;&emsp;PTP的特点： 每个消息只有一个消费者（cunsumes）(即一旦被消费，消息就不再在消息队列中) 发送者和接收者之间在时间上没有依赖性，也就是发送者发送消息后，不管接收者是否接收消息或者接收者服务是否在运行，都不会影响到消息被发送到队列 接收者在成功接收消息之后需向队列应答成功4.2发布-订阅模型（Pub/Sub）&emsp;&emsp;发布-订阅模型（Pub/Sub）包含三个角色：主题（Topic），发布者（Publisher），订阅者（Subscriber） 。多个发布者将消息发送到Topic,系统将这些消息传递给多个订阅者。&emsp;&emsp;Pub/Sub的特点 每个消息可以有多个消费者 发送者和接收者之间在时间上存在依赖性，针对某个主题（Topic）的订阅者，它必须创建一个订阅者之后，才能消费发布者的消息。 为了消费消息，订阅者必须保持运行的状态。 &emsp;&emsp;为了缓和这样严格的时间相关性，JMS允许订阅者创建一个可持久化的订阅。这样，即使订阅者没有被激活（运行），它也能接收到发布者的消息。&emsp;&emsp;如果希望发送的消息可以不被做任何处理、或者只被一个消息者处理、或者可以被多个消费者处理的话，那么可以采用Pub/Sub模型。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.catalpaflat.cn/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.catalpaflat.cn/tags/消息队列/"}]},{"title":"分布式之消息队列","slug":"消息队列/消息队列","date":"2017-07-23T01:20:56.000Z","updated":"2018-03-28T13:02:50.035Z","comments":true,"path":"2017/07/23/消息队列/消息队列/","link":"","permalink":"https://blog.catalpaflat.cn/2017/07/23/消息队列/消息队列/","excerpt":"","text":"分布式之消息队列 目录： 1.消息队列概述 2.消息队列应用场景 2.1应用解耦 2.1.1传统模式 2.1.2使用消息队列 2.2异步处理消息 2.2.1传统模式 2.2.2使用消息队列 2.3流量削锋 2.4日志处理 2.4消息通讯 1.消息队列概述&emsp;&emsp;“消息队列”是在消息的传输过程中保存消息的容器。&emsp;&emsp;消息队列管理器在将消息从它的源中继到它的目标时充当中间人。队列的主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用，消息队列会保留消息，直到可以成功地传递它.&emsp;&emsp;消息队列中间件是分布式系统中重要的组件，主要解决应用耦合、异步消息、流量削锋等问题。实现高性能、高可用、可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。目前在生产环境，使用较多的消息队列有ActiveMQ，RabbitMQ，ZeroMQ，Kafka，MetaMQ，RocketMQ等。 2.消息队列应用场景2.1应用解耦&emsp;&emsp;场景例子：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。 2.1.1传统模式：&emsp;&emsp;&emsp;&emsp;传统模式的缺点：&emsp;&emsp;1）假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；&emsp;&emsp;2）订单系统和库存系统耦合； 2.1.2使用消息队列：&emsp;&emsp;&emsp;&emsp;1）订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。&emsp;&emsp;2）库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。&emsp;&emsp;3）假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。 2.2异步处理消息#### 2.2.1传统模式 ####&emsp;&emsp;场景例子：用户注册后，需要发注册邮件和短信，传统的做法有两种1.串行的方式；2.并行方式。&emsp;&emsp;1)传统串行方式：将注册信息写入数据库后，接着发送注册邮件，再发送短信，等三步骤完成之后再响应客户端&emsp;&emsp;&emsp;&emsp;2）传统并行方式：将注册信息写入数据库后，同时发送注册邮件和短信，等三步骤完成之后再响应客户端。与串行的差别是，并行的方式可以提高处理的时间、缩短响应时间。&emsp;&emsp;&emsp;&emsp;假设三个业务节点每个使用50毫秒钟，不考虑网络等其他开销，则串行方式的时间是150毫秒，并行的时间可能是100毫秒。&emsp;&emsp;因为CPU在单位时间内处理的请求数是一定的，假设CPU1秒内吞吐量是100次。则串行方式1秒内CPU可处理的请求量是7次（1000/150）。并行方式处理的请求量是10次（1000/100）。&emsp;&emsp;传统的方式系统的性能（并发量，吞吐量，响应时间）会有瓶颈。 2.2.2使用消息队列&emsp;&emsp;&emsp;&emsp;1）引入消息队列，除去不必要的业务逻辑，异步处理&emsp;&emsp;2）客户端响应时间相当于注册信息写入库中的时间（由于写入队列时间几乎可以忽略不计）&emsp;&emsp;3）发送注册邮件和短信写入消息队列后，直接返回&emsp;&emsp;4）因此架构改变后，系统的吞吐量提高到每秒20 QPS。比串行提高了3倍，比并行提高了两倍。 2.3流量削锋&emsp;&emsp;流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。&emsp;&emsp;应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。&emsp;&emsp;1）可以控制活动的人数；&emsp;&emsp;2）可以缓解短时间内高流量压垮应用；&emsp;&emsp;加入消息队列示意图：&emsp;&emsp;&emsp;&emsp;1）用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面；&emsp;&emsp;2）秒杀业务根据消息队列中的请求信息，再做后续处理。 2.4日志处理&emsp;&emsp;日志处理是指消息队列应用在日志处理中，比如Kafka的应用（是一种高吞吐量的分布式发布订阅消息系统）解决大量日志传输的问题。架构简化如下：&emsp;&emsp;&emsp;&emsp;架构解读： 日志采集客户端，负责日志数据采集，定时写受写入Kafka队列； Kafka消息队列，负责日志数据的接收，存储和转发； 日志处理应用：订阅并消费kafka队列中的日志数据； 2.5消息通讯&emsp;&emsp;消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。&emsp;&emsp;1）点对点通讯：&emsp;&emsp;&emsp;&emsp;客户端A和客户端B使用同一队列，进行消息通讯。&emsp;&emsp;2）聊天室通讯：&emsp;&emsp;&emsp;&emsp;客户端A，客户端B，客户端N订阅同一主题，进行消息发布和接收。实现类似聊天室效果。&emsp;&emsp;以上实际是消息队列的两种消息模式，点对点或发布订阅模式。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.catalpaflat.cn/categories/消息队列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://blog.catalpaflat.cn/tags/消息队列/"}]},{"title":"Linux Jenkins 安装Jenkins 部署理念","slug":"Jenkins/Jenkins 安装","date":"2017-05-27T14:09:56.000Z","updated":"2018-03-28T13:33:25.133Z","comments":true,"path":"2017/05/27/Jenkins/Jenkins 安装/","link":"","permalink":"https://blog.catalpaflat.cn/2017/05/27/Jenkins/Jenkins 安装/","excerpt":"","text":"Linux Jenkins 安装 安装步骤: 依赖 拉取库的配置到本地对应文件 导入公钥 下载安装jenkins 初始配置jenkins 启动jenkins 设置iptables 配置jenkins Jenkins 官网 1. 依赖部署Jenkins，需有Java - JDK。检测是否安装：1java -version 若没安装可以参考这篇Linux Java-JDK 安装 2. 拉取库的配置到本地对应文件1wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo 3. 导入公钥1rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key 4. 下载安装jenkins1yum -y install jenkins 5. 初始配置jenkins12345vi /etc/sysconfig/jenkins JENKINS_USER=&quot;root&quot; JENKINS_PORT=&quot;6267&quot; //JENKINS_ARGS=&quot;--prefix=/jenkins&quot; JENKINS_JAVA_OPTIONS=&quot;-Djava.awt.headless=true -Dhudson.util.ProcessTree.disable=true&quot; 6. 启动jenkins1service jenkins start 7. 设置iptables1vi /etc/sysconfig/iptables 开放端口：1-A INPUT -p tcp -m tcp --dport 6257 -j ACCEPT 重启iptables!()[img/j1.jpg]1service iptables restart 8. 配置jenkins8.1访问jenkins访问 http://localhost:6257初期启动需要密码（密码在这个文件里：/var/lib/jenkins/secrets/initialAdminPassword） 8.2 安装插件（查看安装日志：/var/log/jenkins/jenkins.log）如果安装插件过程有错误，可以不用管，之后还可以通过Dashboard管理插件： 8.3 创建用户 8.4 安装成功","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://blog.catalpaflat.cn/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://blog.catalpaflat.cn/tags/Jenkins/"}]},{"title":"Jenkins 部署理念","slug":"Jenkins/JenKin部署","date":"2017-05-26T07:53:56.000Z","updated":"2018-03-28T13:32:38.057Z","comments":true,"path":"2017/05/26/Jenkins/JenKin部署/","link":"","permalink":"https://blog.catalpaflat.cn/2017/05/26/Jenkins/JenKin部署/","excerpt":"","text":"Jenkins 部署理念 Jenkins是一个开源软件项目，是基于Java开发的一种持续集成工具，用于监控持续重复的工作. 1.Jenkins简述目前持续集成(CI)已成为当前许多软件开发团队在整个软件开发生命周期内侧重于保证代码质量的常见做法。它是一种实践，旨在缓和和稳固软件的构建过程。并且能够帮助您的开发团队应对如下挑战： 软件构建自动化 ：配置完成后，CI系统会依照预先制定的时间表，或者针对某一特定事件，对目标软件进行构建。 构建可持续的自动化检查 ：CI系统能持续地获取新增或修改后签入的源代码，也就是说，当软件开发团队需要周期性的检查新增或修改后的代码时，CI系统会不断确认这些新代码是否破坏了原有软件的成功构建。这减少了开发者们在检查彼此相互依存的代码中变化情况需要花费的时间和精力 构建可持续的自动化测试 ：构建检查的扩展部分，构建后执行预先制定的一套测试规则，完成后触发通知(Email,RSS等等)给相关的当事人。 生成后后续过程的自动化 :当自动化检查和测试成功完成，软件构建的周期中可能也需要一些额外的任务，诸如生成文档、打包软件、部署构件到一个运行环境或者软件仓库。这样，构件才能更迅速地提供给用户使用。 部署一个CI系统需要的最低要求是，一个可获取的源代码的仓库，一个包含构建脚本的项目。2.Jenkins运行分析简要分析：首先要有统一的代码库，服务器不断从版本控制服务器上检查代码状态，看代码是否有更新。如果发现有代码更新，那么就从版本控制服务器下载最新的代码。等代码完全更新以后，调用自动化编译脚本，进行代码编译。然后运行所有的自动化测试，并且进行代码分析。如果其中任何一个步骤失败，就表示build失败，持续集成服务器会给予响应的反馈。每次代码提交之后，都会在持续集成服务器上触发一个定时构建，然后进行编译、部署。","categories":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://blog.catalpaflat.cn/categories/Jenkins/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://blog.catalpaflat.cn/tags/Jenkins/"}]},{"title":"JavaEE 使用Gradle发布jar包到远程中央仓库","slug":"JavaEE/packaging/JavaEE 使用Gradle发布jar包到远程中央仓库","date":"2017-03-23T07:53:56.000Z","updated":"2018-03-28T13:19:25.191Z","comments":true,"path":"2017/03/23/JavaEE/packaging/JavaEE 使用Gradle发布jar包到远程中央仓库/","link":"","permalink":"https://blog.catalpaflat.cn/2017/03/23/JavaEE/packaging/JavaEE 使用Gradle发布jar包到远程中央仓库/","excerpt":"","text":"JavaEE 使用Gradle发布jar包到远程中央仓库0. 前提准备GitHub 上 New Repository 项目（若没有则注册）. 1. 创建Bintray账号前往 Bintray ，右上角点击 Sign In 跳转到登录页面，可以选择通过第三方账号登录或者自己注册一个，方便起见我直接用了Github账号。 . 2. Bintray上创建maven仓库登录后点击左侧的 Add new Repository按钮 跳转到创建仓库的页面，Name一栏填写仓库的名字，这里我写的是maven，仓库类型选 Maven ，创建完成后仓库就可以使用了。 3. 获取BINTRAY_KEY其中 BINTRAY_KEY 的值设为Api key，从下图所示位置获取: 4. 注册JIRA账号注册链接注册之后请妥善保管好账号密码，后续登录相关Nexus链接需要用到。 5. 创建issue注册完之后创建ISSUE. 6. GPG签名GPG(GnuPG)是一款非对称加密软件，上传的Jar包需要用GPG生成签名文件，否则是不能同步到MavenCentral的，使用GPG给文件签名需要有公钥，可以用Bintray提供的默认的公钥或者使用自己生成的公钥，以下两种方法二选一。 6.1 较简单方法该方法比较便捷，不需要进行生成密钥等繁琐操作。首先进入你创建的仓库页面，点击 Edit ，进入编辑页面 然后勾选如图所示的选项，当你上传Jar文件时系统就会自动帮你生成签名文件。 . 6.2 较复杂方法1. 下载GPG1.下载安装。 (1) Mac操作系统： 1brew install gnupg (2) Windows操作系统下载地址：https://www.gpg4win.org/ 2.校验 1gpg --version 2. 配置GPG生成对称签名1gpg --gen-key 1.输入姓名和邮箱2.输入passphrase密码3.记住密钥，用于上传 3. 上传GPG签名123456789101112131415161718192021222324252627282930313233343536373839gpg --keyserver hkp://keys.gnupg.net --send-keys 上图圈出来的密钥``` ![](img/WechatIMG11.jpeg) #### 4. 回Bintray的界面(1).点击右上角导航栏的头像，点击 Edit Profile。 ![](https://upload-images.jianshu.io/upload_images/4675459-284e0e5a1b672ff1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/232) (2).跳转到以下页面，点击GPG Signing。 ![](https://upload-images.jianshu.io/upload_images/4675459-4f8038756be33ed9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/292) (3).把刚才导出的公钥和私钥粘贴进去，包括虚线的两行文本，然后点击 Update。![](https://upload-images.jianshu.io/upload_images/4675459-a60a639f88a40cfa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/583) #### 5. 回到仓库页面，点击Edit![](https://upload-images.jianshu.io/upload_images/4675459-627856113530cc2f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/627) #### 6.开启自动签名功能，配置就完成了![](https://upload-images.jianshu.io/upload_images/4675459-cfe3b95c277d369a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700) ## 7.获取OSSRH_TOKEN信息### 1.使用Sonatype账号[登录](https://oss.sonatype.org)，点击 Profile ![](https://upload-images.jianshu.io/upload_images/4675459-dddadef2a64dbab8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/440)### 2.点击 Access User Token 查看你的Token![](https://upload-images.jianshu.io/upload_images/4675459-075ea8a731642ca6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700). 左边输入框是你的username，右边是你的密码，建议把账号有关的信息从环境变量中读取，不要提交到VCS中。 ![](https://upload-images.jianshu.io/upload_images/4675459-c04e5d7025d05998.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700)## 8. 配置项目bulid.gradle### 1. gradle.properties. DEVELOPER_ID=CatalpaFlatDEVELOPER_NAME=CatalpaFlatDEVELOPER_EMAIL=catalpaflat@outlook.com PROJ_NAME=xxxPROJ_GROUP=com.github.catalpaflatPROJ_ARTIFACTID=xxxPROJ_DESCRIPTION=xxxPROJ_VERSION=1.0.0PROJ_WEBSITEURL=https://github.com/CatalpaFlat/xxxxPROJ_ISSUETRACKERURL=https://github.com/CatalpaFlat/xxxx/issues12### 2. local.properties. BINTRAY_USER=catalpaflatBINTRAY_KEY=xxxxx OSSRH_USER=xxxOSSRH_PASSWORD=xxxxxxx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150### 3. bulid.gradle. ```gradlebuildscript &#123; repositories &#123; google() jcenter() //使用阿里的maven镜像 maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public&apos; &#125; &#125; dependencies &#123; //引入bintray插件 classpath &apos;com.jfrog.bintray.gradle:gradle-bintray-plugin:1.7.3&apos; &#125;&#125;group = PROJ_GROUPversion = PROJ_VERSIONapply plugin: &apos;maven&apos;apply plugin: &apos;java-library&apos;apply plugin: &apos;maven-publish&apos;apply plugin: &apos;com.jfrog.bintray&apos;apply plugin: &apos;idea&apos;apply plugin: &apos;java&apos;sourceCompatibility = 1.8targetCompatibility = 1.8//生成源文件task sourcesJar(type: Jar, dependsOn: classes) &#123; classifier = &apos;sources&apos; from sourceSets.main.allSource&#125;//文档打包成jartask javadocJar(type: Jar, dependsOn: javadoc) &#123; classifier = &apos;javadoc&apos; from javadoc.destinationDir&#125;//上传到JCenter所需要的源码文件artifacts &#123; archives javadocJar archives sourcesJar&#125;def pomConfig = &#123; licenses &#123; license &#123; //开源协议 name &apos;The Apache Software License, Version 2.0&apos; url &apos;http://www.apache.org/licenses/LICENSE-2.0.txt&apos; &#125; &#125; developers &#123; developer &#123; //开发者的个人信息 id &apos;CatalpaFlat&apos; name &apos;CatalpaFlat&apos; email &quot;catalpaflat@outlook.com&quot; &#125; &#125; scm &#123; connection &quot;https://github.com/CatalpaFlat/xxxx.git&quot; developerConnection &quot;https://github.com/CatalpaFlat/xxxx.git&quot; //项目网站 url &quot;https://github.com/CatalpaFlat/xxxx&quot; &#125;&#125;publishing &#123; publications &#123; MyPublication(MavenPublication) &#123; from components.java artifact sourcesJar artifact javadocJar groupId &apos;com.github.catalpaflat&apos; artifactId &apos;SMS-modularization&apos; version &apos;1.0.1&apos; pom.withXml &#123; def root = asNode() root.appendNode(&apos;description&apos;, &apos;XXXX&apos;) root.appendNode(&apos;name&apos;, &apos;XXXX&apos;) root.appendNode(&apos;url&apos;, &apos;https://github.com/CatalpaFlat/xxxx&apos;) root.children().last() + pomConfig &#125; &#125; &#125;&#125;task writeNewPom &lt;&lt; &#123; pom &#123; project &#123; inceptionYear &apos;2018&apos; licenses &#123; license &#123; name &apos;The Apache Software License, Version 2.0&apos; url &apos;http://www.apache.org/licenses/LICENSE-2.0.txt&apos; distribution &apos;repo&apos; &#125; &#125; developers &#123; developer &#123; //开发者的个人信息 id &apos;CatalpaFlat&apos; name &apos;CatalpaFlat&apos; email &quot;catalpaflat@outlook.com&quot; &#125; &#125; scm &#123; connection &quot;https://github.com/CatalpaFlat/xxxx.git&quot; developerConnection &quot;https://github.com/CatalpaFlat/xxxx.git&quot; //项目网站 url &quot;https://github.com/CatalpaFlat/xxxx&quot; &#125; &#125; &#125;.writeTo(&quot;pom.xml&quot;)&#125;bintray &#123; Properties properties = new Properties() properties.load(project.rootProject.file(&apos;local.properties&apos;).newDataInputStream()) user = properties.getProperty(&apos;BINTRAY_USER&apos;) key = properties.getProperty(&apos;BINTRAY_KEY&apos;) configurations = [&apos;archives&apos;] publications = [&apos;xxxx&apos;] dryRun = false publish = true pkg &#123; repo = &apos;maven&apos; name = PROJ_NAME licenses = [&apos;Apache-2.0&apos;] vcsUrl = &apos;https://github.com/CatalpaFlat/xxx.git&apos; websiteUrl = &apos;https://github.com/CatalpaFlat/xxx&apos; issueTrackerUrl = PROJ_ISSUETRACKERURL labels = [&apos;java&apos;, &apos;spring&apos;, &apos;example&apos;] version &#123; name = PROJ_VERSION desc = PROJ_DESCRIPTION released = new Date() vcsTag = PROJ_VERSION &#125; &#125;&#125; 9. release1.执行gradle命令进行发布： 1./gradlew bintrayUpload 2.让我们回到Bintray上之前创建的maven仓库，这时你能在仓库的页面看到你刚才上传的包了，类似下图： . 3.点击包名，跳转后，在页面的右侧你会找到 Add to JCenter 的按钮，点击它继续跳转. . 你可以填写一些信息，也可以直接点击Send，过一段时间，系统会发送邮件提示你申请已经通过。 . 4.再回到刚才包的页面，点击 Maven Central，输入你的Sonatype的Token信息点击Sync，就可以完成同步了。第一次同步成功后，Sonatype也会通过邮件告知你 。 注：以后再发布新版本的时候直接执行Gradle命令就行了。同步完成后可以马上在 https://oss.sonatype.org 进行搜索，但是 https://mvnrepository.com/ 的搜索并不是实时的，需要等待一段时间，通常搜索结果第二天就能更新。","categories":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://blog.catalpaflat.cn/categories/JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://blog.catalpaflat.cn/tags/JavaEE/"}]},{"title":"JavaEE 使用Maven发布jar包到远程中央仓库","slug":"JavaEE/packaging/JavaEE 使用Maven发布jar包到远程中央仓库","date":"2017-03-23T07:00:56.000Z","updated":"2018-03-28T13:28:15.418Z","comments":true,"path":"2017/03/23/JavaEE/packaging/JavaEE 使用Maven发布jar包到远程中央仓库/","link":"","permalink":"https://blog.catalpaflat.cn/2017/03/23/JavaEE/packaging/JavaEE 使用Maven发布jar包到远程中央仓库/","excerpt":"","text":"JavaEE 使用Maven发布jar包到远程中央仓库0. 前提准备GitHub 上 New Repository 项目（若没有则注册）. 1. Sonatype OSSRH 简介Sonatype OSSRH 使用Nexus 为开源项目提供仓库管理服务，该仓库就是所谓maven的中央仓库，OSSRH允许我们向Maven中央仓库提交二进制文件。使用Sonatype OSSRH可以做以下操作： 提交(deploy)开发版本的二进制文件（snapshorts) 阶段性的发布版本 发布一个release,同步到Sonatype OSSRH 中央仓库。 总共就两种版本：snapshorts版本（开发版本）和release（发布版本） 2. 注册JIRA账号注册链接注册之后请妥善保管好账号密码，后续登录相关Nexus链接需要用到。 3. 创建issue注册完之后创建ISSUE 注： 当创建完之后，issue的status为open状态，此时还不能进行上传jar，若group id为com.github开头的话，基本秒过（管理员审核较快，即从OPEN -&gt; RESOLVED）,当为RESOLVED时，即上传jar。 当ISSUA转为RESOLVED时，会有附带相关链接,其中只需记录这两个链接： Deploy snapshot artifacts into repository Deploy release artifacts into the staging repository 后续配置项目pom.xml时需要 4. 下载GPG1.下载安装。 (1) Mac操作系统： 1brew install gnupg (2) Windows操作系统下载地址：https://www.gpg4win.org/ 2.校验 1gpg --version 5. 配置GPG生成对称签名1gpg --gen-key 1.输入姓名和邮箱2.输入passphrase密码3.记住密钥，用于上传 6. 上传GPG签名12345678910111213141516171819202122232425gpg --keyserver hkp://keys.gnupg.net --send-keys 上图圈出来的密钥``` ![](img/WechatIMG11.jpeg) ### 7. IDEA 创建maven项目此处无图### 8. 配置maven下config的setting.xml配置JIRA账号，用于发布snapshorts版本。 ```xml&lt;server&gt; &lt;id&gt;sonatype-nexus-snapshots&lt;/id&gt; &lt;username&gt; account &lt;/username&gt; &lt;password&gt; password &lt;/password&gt;&lt;/server&gt;&lt;server&gt; &lt;id&gt;sonatype-nexus-staging&lt;/id&gt; &lt;username&gt; account &lt;/username&gt; &lt;password&gt; password d&lt;/password&gt;&lt;/server&gt;&lt;/servers&gt; 9.配置项目pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.github.youname&lt;/groupId&gt; &lt;artifactId&gt;XXXX&lt;/artifactId&gt; &lt;!-- 若发布snapshorts版本，则需添加版本后缀 '-SNAPSHOT' --&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- org.sonatype.oss依赖--&gt; &lt;parent&gt; &lt;groupId&gt;org.sonatype.oss&lt;/groupId&gt; &lt;artifactId&gt;oss-parent&lt;/artifactId&gt; &lt;version&gt;7&lt;/version&gt; &lt;/parent&gt; &lt;!-- 默认许可证 --&gt; &lt;licenses&gt; &lt;license&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!-- GitHub项目地址 --&gt; &lt;scm&gt; &lt;url&gt;https://github.com/CatalpaFlat/XXX&lt;/url&gt; &lt;connection&gt;https://github.com/CatalpaFlat/XXX.git&lt;/connection&gt; &lt;/scm&gt; &lt;!-- 开源项目作者信息 --&gt; &lt;developers&gt; &lt;developer&gt; &lt;name&gt;CatalpaFlat&lt;/name&gt; &lt;email&gt;youemail&lt;/email&gt; &lt;url&gt;https://github.com/CatalpaFlat/XXX&lt;/url&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;/profiles&gt; &lt;profile&gt; &lt;!-- 部署release版本要用到 --&gt; &lt;id&gt;release&lt;/id&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonatype.plugins&lt;/groupId&gt; &lt;artifactId&gt;nexus-staging-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.3&lt;/version&gt; &lt;extensions&gt;true&lt;/extensions&gt; &lt;configuration&gt; &lt;serverId&gt;ossrh&lt;/serverId&gt; &lt;nexusUrl&gt;https://oss.sonatype.org/&lt;/nexusUrl&gt; &lt;autoReleaseAfterClose&gt;true&lt;/autoReleaseAfterClose&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;configuration&gt; &lt;autoVersionSubmodules&gt;true&lt;/autoVersionSubmodules&gt; &lt;useReleaseProfile&gt;false&lt;/useReleaseProfile&gt; &lt;releaseProfiles&gt;release&lt;/releaseProfiles&gt; &lt;goals&gt;deploy&lt;/goals&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt; &lt;version&gt;1.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;sign-artifacts&lt;/id&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sign&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.9&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;!-- 这个id需要在setting.xml中设置对应 --&gt; &lt;id&gt;sonatype-nexus-snapshots&lt;/id&gt; &lt;name&gt;OSS Snapshots Repository&lt;/name&gt; &lt;!-- 这里的url就是Issue中回复的snapshots 的repo地址--&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;repository&gt; &lt;id&gt;sonatype-nexus-staging&lt;/id&gt; &lt;name&gt;OSS Staging Repository&lt;/name&gt; &lt;!-- 这里的url就是Issue中回复的staging 的repo地址--&gt; &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt; 10. 发布snapshorts版本修改version加一个-SNAPSHOT. 1mvn clean deploy 11. 发布release版本修改version 不要加-SNAPSHOT. 1mvn clean deploy -P release 12. close 项目/release 项目使用注册的账号登录:Nexus Repository Manager 注：查看自己的(你定义的版本号不能带SNAPSHOT要不然看不到)a）构件准备好之后，在命令行上传构建；b）在https://oss.sonatype.org/ 先“close”后“release”构件；c) 等待同步好（大约2小时多）之后，就可以使用了。 13. 设置上传中央仓库Already Synced to Central设置为Yes 14. 查询发布结果Central Repositiry","categories":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://blog.catalpaflat.cn/categories/JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://blog.catalpaflat.cn/tags/JavaEE/"}]},{"title":"JavaEE 发布jar包到远程maven中央仓库","slug":"JavaEE/packaging/JavaEE 发布jar包到远程maven中央仓库","date":"2017-03-22T03:33:56.000Z","updated":"2018-03-28T13:19:49.433Z","comments":true,"path":"2017/03/22/JavaEE/packaging/JavaEE 发布jar包到远程maven中央仓库/","link":"","permalink":"https://blog.catalpaflat.cn/2017/03/22/JavaEE/packaging/JavaEE 发布jar包到远程maven中央仓库/","excerpt":"","text":"JavaEE 发布jar包到远程maven中央仓库 当项目成熟到一定阶段时，需要将相关业务模块抽离封装迭代管理时，可以将业务相关内容模块化，并将其打包到对应远程仓库，以此提高下次开发效率与成本。其中，JavaEE就有两种打包方法： maven ——Nexus仓库 gradle —— JCenter仓库 两者都可以将jar提交到远程仓库中。 一.Maven方法 使用Sonatype OSSRH 将 开源项目的jar 交给Maven的中央仓库。 Nexus Repository Manager: https://oss.sonatype.org Sonatype: https://issues.sonatype.org Central Repositiry: https://search.maven.org 简要步骤： GitHub 上创建对应开源项目Repository 注册JIRA账号 — 远程maven仓库账号 创建issue — 其中关联GitHub项目链接 下载GPG（用于签名） 配置GPG对称签名 ——Remember passphrase/Remember the User Id（密钥） 上传GPG签名（发布Release版本关键） IDEA 创建maven项目 配置maven下config的setting.xml（snapshorts版本关键） 配置项目pom.xml 发布snapshorts版本 发布release版本 close 项目 release 项目 设置上传中央仓库 Integral flow chart The specific implementationJavaEE 使用Maven发布jar包到远程中央仓库 二.Gradle方法 使用 Bintray 将 开源项目的jar 交给Maven的中央仓库。 Bintray: https:/bintray.com Sonatype: https://issues.sonatype.org 简要步骤： 创建Bintray账号 Bintray上创建maven仓库 获取BINTRAY_KEY 注册JIRA账号 — 远程maven仓库账号 创建issue — 其中关联GitHub项目链接 GPG签名 - 配置到Bintray 获取OSSRH_TOKEN信息（关联issue的凭证） - 配置bulid.gradle和后续Release IDEA 创建Gradle项目 配置项目bulid.gradle - 关联issue/关联Bintray 发布部署 Integral flow chart The specific implementationJavaEE 使用Gradle发布jar包到远程中央仓库","categories":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://blog.catalpaflat.cn/categories/JavaEE/"}],"tags":[{"name":"JavaEE","slug":"JavaEE","permalink":"https://blog.catalpaflat.cn/tags/JavaEE/"}]},{"title":"虚拟机CentOS6.7 快速安装redis","slug":"服务器/虚拟机CentOS6.7 快速安装redis","date":"2016-11-23T14:13:21.000Z","updated":"2018-03-28T13:01:19.859Z","comments":true,"path":"2016/11/23/服务器/虚拟机CentOS6.7 快速安装redis/","link":"","permalink":"https://blog.catalpaflat.cn/2016/11/23/服务器/虚拟机CentOS6.7 快速安装redis/","excerpt":"","text":"虚拟机CentOS6.7 快速安装redis1.配置编译环境yum -y install gcc-c++ 2.下载redis安装包wget http://download.redis.io/releases/redis-3.2.8.tar.gz 3.解压源码tar -zxvf redis-3.2.8.tar.gz -C /usr/local/ 4.进入源码目录cd /usr/local/redis-3.2.8 5.编译redismake MALLOC=libc tips：make命令执行完成编译后，会在src目录下生成6个可执行文件，分别是redis-server、redis-cli、redis-benchmark、redis-check-aof、redis-check-rdb、redis-sentinel。 6.安装redismake install 7.配置Redis能随系统启动./utils/install_server.sh 一直enter到底 8.查看redis进程ps =ef|grep redis 9.操作redis服务/etc/init.d/redis_6379 start 开启（service redis_6379 start） /etc/init.d/redis_6379 stop 关闭（service redis_6379 stop） /etc/init.d/redis_6379 status 状态（service redis_6379 status）","categories":[{"name":"服务器","slug":"服务器","permalink":"https://blog.catalpaflat.cn/categories/服务器/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.catalpaflat.cn/tags/服务器/"}]},{"title":"虚拟机快速搭建CentOS，并解决网络问题","slug":"服务器/虚拟机快速搭建CentOS，并解决网络问题","date":"2016-11-23T06:20:56.000Z","updated":"2018-03-28T13:00:47.618Z","comments":true,"path":"2016/11/23/服务器/虚拟机快速搭建CentOS，并解决网络问题/","link":"","permalink":"https://blog.catalpaflat.cn/2016/11/23/服务器/虚拟机快速搭建CentOS，并解决网络问题/","excerpt":"","text":"虚拟机快速搭建CentOS，并解决网络问题1.搭建环境： 虚拟机：VMware Workstation12 镜像：CentOS-6.7-x86_64-bin-DVD1.iso 网络设配器：NAT模式 主机：window7 Vmware提供了三种网络连接模式：1.bridged(桥接模式):默认使用VMnet0，不提供DHCP服务简述：虚拟机和宿主计算机处于同等地位，虚拟机就像是一台真实主机一样存在于局域网中。2.NAT(网络地址转换模式):默认使用VMnet8，提供DHCP服务简述：宿主计算机相当于一台开启了DHCP功能的路由器，而虚拟机则是内网中的一台真实主机，通过路由器(宿主计算机)DHCP动态获得网络参数。因此在NAT模式下，虚拟机可以访问外部网络。使用NAT模式的方便之处在于，我们不需要做任何网络设置，只要宿主计算机可以连接到外部网络，虚拟机也可以。3.Host-only(主机模式):默认使用VMnet1，提供DHCP服务简述：在Host-only模式下，相当于虚拟机通过双绞线和宿主计算机直连，而宿主计算机不提供任何路由服务。因此在Host-only模式下，虚拟机可以和宿主计算机互相访问，但是虚拟机无法访问外部网络。当我们要组成一个与物理网络相隔离的虚拟网络时，无疑非常适合使用Host-only模式。 好了，接下来继续！ 2.编辑虚拟网络编辑器1).编辑-&gt;虚拟网络编辑器-&gt;更改配置2).选择VMnet8-&gt;取消勾选使用本地DHCP-&gt;设置子网IP-&gt;NAT设置-&gt;网关IP设置说明：修改子网IP设置，实现自由设置固定IP。若你想设置固定IP为192.168.6.2-255，比如192.168.6.111，则子网IP为192.168.6.0，网关192.168.6.1. 3.虚拟机网络设配器虚拟机-&gt;设置-&gt;选择NAT模式 4.宿主机（即本机）VMnet8配置控制面板-&gt;网络和 Internet-&gt;网络连接-&gt;VMware Network Adapter VMnet8 5.虚拟机安装CentOS的流程网上一抓一大把，所以这里就不详细说明，最主要是前面几步6.配置CentOS 静态ipvi /etc/sysconfig/network-scripts/ifcfg-eth0 7.配置静态ipDEVICE=eth0 HWADDR=00:0C:29:8D:2B:41 TYPE=Ethernet UUID=a5d920bf-b096-4bdd-aa75-7a60b982aa19 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=192.168.6.111 NETMASK=255.255.255.0 GATEWAY=192.168.6.1 DNS1=114.114.114.114 8.重启networlservice network restart 9.查看当前ip是否配置成功ifconfig -a 10.主虚互ping 虚拟机搭建CentOS已经完成，并且网络配置已经调通。","categories":[{"name":"服务器","slug":"服务器","permalink":"https://blog.catalpaflat.cn/categories/服务器/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"https://blog.catalpaflat.cn/tags/服务器/"}]},{"title":"Java中的各种O","slug":"java/Java 实体","date":"2016-07-23T05:20:56.000Z","updated":"2018-03-28T12:55:23.839Z","comments":true,"path":"2016/07/23/java/Java 实体/","link":"","permalink":"https://blog.catalpaflat.cn/2016/07/23/java/Java 实体/","excerpt":"","text":"展示层 → 接口层 → 服务层 → 数据访问层 → 持久层 ↓ ↑ 业务逻辑层 layer： IDAL(接口层) service(服务层) BLL(业务逻辑层) DAL(数据访问层) Persistent(持久层) class： VO（View Object）：视图对象，用于展示层，它的作用是把某个指定页面（或组件）的所有数据封装起来。 DTO（Data Transfer Object）：数据传输对象，这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载.但在Dankal，我们泛指用于展示层与服务层之间的数据传输对象。 DO（Domain Object）：领域对象，就是从现实世界中抽象出来的有形或无形的业务实体。 PO（Persistent Object）：持久化对象，它跟持久层（通常是关系型数据库）的数据结构形成一一对应的映射关系，如果持久层是关系型数据库，那么，数据表中的每个字段（或若干个）就对应PO的一个（或若干个）属性。（数据库表的一条记录） TO(Transfer Object):数据传输对象,在应用程序不同tie(关系)之间传输的对象. BO(business object)：业务对象（BO用来封装多个PO），从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法,结合PO,VO进行业务操作。 POJO(plain ordinary java object)：简单无规则java对象 纯的传统意义的java对象。最基本的Java Bean，只有属性字段及setter和getter方法！没有其他封装方法。 frame: BOF Business Object Framework 业务对象框架 EMF Eclipse Model Framework Eclipse 建模框架 design: SOA Service Orient Architecture 面向服务的设计 DALFactory(类工厂)","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/tags/Java/"}]},{"title":"Java JVM 内存详解","slug":"java/Java 内存详解","date":"2016-03-23T07:53:56.000Z","updated":"2018-03-28T13:21:51.653Z","comments":true,"path":"2016/03/23/java/Java 内存详解/","link":"","permalink":"https://blog.catalpaflat.cn/2016/03/23/java/Java 内存详解/","excerpt":"","text":"[TOC] Java JVM 内存详解一、Java内存分配(数据存储区域)：1. 程序计数器（Program Counter Register） 当前线程所执行的字节码行号指示器 一块较小的内存空间 线程私有内存 由于Java虚拟机是多线程的，因此在多线程执行时候，其实是线程之间的轮流切换从而来获取CPU的处理，因此想要记录当前线程上一步所执行到哪里，就是通过程序计数器，这样就能在下次当前线程获取CPU的执行权的时候，能够正常继续执行。因此每一条线程都其自身的程序计数器，线程间互补影响，独立存储。 2. Java 虚拟机栈 当前执行方法的内存模型 线程私有内存 当一个方法被执行时，会创建一个栈帧用来存储： 局部变量表 操作栈 动态链接 方法出口 ……其实Java虚拟机栈就是我们经常所说的“栈内存”其中64位长度的long和double类型的数据会占用2个局部变量空间（Slot），其余的数据类型只占用1个。局部变量表所需要的内存空间，在编译期完全分配好，当进入一个方法，这个方法需要在帧中分配多大的局部变量表内存空间是完全群的，不会在方法运行时改变局部变量表的大小。 3. 本地方法栈本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别不过是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的Native方法服务。 4. 堆Java堆（Java Heap）是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 5. 方法区方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 5.1 运行时常量池：运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述等信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 二、Java对象的内存创建、内存布局、内存访问1. 对象内存创建1）使用new123 -&gt; (有) 是否已经加载、解析、初始化 -&gt; 指针碰撞 -&gt; 进行同步处理常量池 -&gt; （检索）是否有该类的符号引用 -&gt; 分配内存 -&gt;(分配时的线程安全) -&gt;(初始化) -&gt; (无) 加载 、解析 -&gt; 空闲列表 -&gt; TLAB(线程缓冲) 2）赋值引用123 -&gt; 存在 -&gt; 栈中的reference指向对象堆 -&gt; (查询是否存在) -&gt; 不存在 -&gt; null 2. 对象内存布局123 -&gt; 对象头布局 -&gt; 实例数据 -&gt; 对齐填充 123 -&gt; 1)存储对象自身的运行时数据，如哈希吗、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等1.对象头： -&gt; 2)类型指针，指向它的类元数据（元数据即关于数据的数据），虚拟机通过这个指针确定这个对象是哪个类的实例。 实例数据：对象真正存储的有效信息，也是在代码中所定义的各种类型的字段内容。无论是从父类继承的还是子类中定义的，都需要记录起来。 对齐填充：并不是必然存在的，仅仅起着占位符的作用。HotSpot的自动内存管理系统要求对象起始地址必须是8字节的整数倍，因此当对象实例数据部分没有对齐时，需要对齐填充来补全。 3. 对象内存访问-&gt; 句柄 访问方式 -&gt; 直接指针 句柄：Java堆中会划分出一块内存作为句柄池，栈中的reference指向对象的句柄地址，句柄中包含了对象实例数据和类型数据各自的具体地址信息。 直接指针：reference中存储的就是对象地址 使用句柄访问的最大好处就是reference中存储的是稳定的句柄地址，对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，reference本身不需要修改。使用直接指针访问的最大好处就是速度快，节省了一次指针定位的时间开销。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.catalpaflat.cn/tags/Java/"}]}]}